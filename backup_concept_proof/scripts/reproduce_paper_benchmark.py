#!/usr/bin/env python3
"""
WASS-RAG Paper Benchmark Reproduction Script

This script generates synthetic benchmark data similar to the paper's results,
demonstrating different scheduling strategies on workflow types.

The results are conceptual and use simplified models, not full WRENCH simulation.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple
import json
from pathlib import Path
import sys
import os

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from utils import setup_logger, time_stage

class BenchmarkReproduction:
    """Reproduce paper benchmark results with synthetic data"""
    
    def __init__(self):
        self.logger = setup_logger("BenchmarkReproduction")
        self.workflow_types = ["Linear Chain", "Fan-in", "Fan-out"]
        self.schedulers = [
            "Traditional Slurm",
            "HEFT", 
            "WASS (Heuristic)",
            "WASS-DRL (w/o RAG)",
            "WASS-RAG"
        ]
        
        # Base complexities for different workflow types
        self.base_complexity = {
            "Linear Chain": 250,  # Sequential bottleneck
            "Fan-in": 420,        # Data aggregation complexity
            "Fan-out": 380        # Data distribution complexity
        }
        
        # Improvement factors for each scheduler (relative to Traditional Slurm)
        self.improvement_factors = {
            "Traditional Slurm": 1.0,      # Baseline
            "HEFT": 0.86,                  # ~14% improvement (classic algorithm)
            "WASS (Heuristic)": 0.76,      # ~24% improvement (data locality)
            "WASS-DRL (w/o RAG)": 0.70,    # ~30% improvement (learning)
            "WASS-RAG": 0.65               # ~35% improvement (knowledge-guided)
        }
        
    def generate_realistic_makespan(self, workflow_type: str, scheduler: str) -> float:
        """Generate realistic makespan with some variance"""
        base = self.base_complexity[workflow_type]
        factor = self.improvement_factors[scheduler]
        
        # Add workflow-specific scheduler effects
        if scheduler == "HEFT" and workflow_type == "Fan-out":
            factor *= 1.05  # HEFT less effective on fan-out
        elif scheduler == "WASS (Heuristic)" and workflow_type == "Linear Chain":
            factor *= 0.95  # Data locality very effective on linear chains
        elif scheduler == "WASS-RAG" and workflow_type == "Fan-in":
            factor *= 0.92  # RAG excellent for complex aggregation patterns
            
        # Add realistic noise (Â±3%)
        noise = np.random.normal(1.0, 0.03)
        
        return int(base * factor * noise)
    
    def generate_paper_benchmark_data(self) -> pd.DataFrame:
        """Generate benchmark data matching paper format"""
        results = []
        
        # Set seed for reproducible results
        np.random.seed(42)
        
        for workflow_type in self.workflow_types:
            row = {"Workflow Type": workflow_type}
            
            for scheduler in self.schedulers:
                makespan = self.generate_realistic_makespan(workflow_type, scheduler)
                row[scheduler] = makespan
                
            results.append(row)
            
        return pd.DataFrame(results)
    
    def calculate_improvements(self, df: pd.DataFrame) -> pd.DataFrame:
        """Calculate improvement percentages"""
        improvements = df.copy()
        
        for workflow_type in self.workflow_types:
            row_idx = df[df["Workflow Type"] == workflow_type].index[0]
            baseline = df.loc[row_idx, "Traditional Slurm"]
            
            for scheduler in self.schedulers[1:]:  # Skip baseline
                current = df.loc[row_idx, scheduler]
                improvement = ((baseline - current) / baseline) * 100
                improvements.loc[row_idx, f"{scheduler} (% imp.)"] = f"{improvement:.1f}%"
                
        return improvements
    
    def create_paper_style_table(self, df: pd.DataFrame) -> str:
        """Create paper-style formatted table"""
        table_lines = []
        
        # Header
        table_lines.append("-" * 74)
        table_lines.append("Workflow   Traditional   HEFT (s) WASS          WASS-DRL (w/o   WASS-RAG")
        table_lines.append("Type       Slurm (s)              (Heuristic)   RAG) (s)        (s)")
        table_lines.append("                                  (s)                           ")
        table_lines.append("---------- ------------- -------- ------------- --------------- ----------")
        
        # Data rows
        for _, row in df.iterrows():
            workflow = row["Workflow Type"]
            # Truncate workflow name if too long
            if workflow == "Linear Chain":
                workflow = "Linear"
            
            line = f"{workflow:<10} {row['Traditional Slurm']:<13} {row['HEFT']:<8} " \
                   f"{row['WASS (Heuristic)']:<13} {row['WASS-DRL (w/o RAG)']:<15} {row['WASS-RAG']:<10}"
            table_lines.append(line)
            
            # Add empty line for chain (matching paper format)
            if workflow == "Linear":
                table_lines.append("Chain" + " " * 69)
        
        table_lines.append("-" * 74)
        
        return "\n".join(table_lines)
    
    def create_visualization(self, df: pd.DataFrame) -> None:
        """Create benchmark visualization"""
        plt.figure(figsize=(14, 8))
        
        # Prepare data for plotting
        x = np.arange(len(self.workflow_types))
        width = 0.15
        
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57']
        
        for i, scheduler in enumerate(self.schedulers):
            makespans = [df[df["Workflow Type"] == wf][scheduler].iloc[0] 
                        for wf in self.workflow_types]
            plt.bar(x + i * width, makespans, width, label=scheduler, 
                   color=colors[i], alpha=0.8)
        
        plt.xlabel('Workflow Type', fontsize=12, fontweight='bold')
        plt.ylabel('Makespan (seconds)', fontsize=12, fontweight='bold')
        plt.title('WASS-RAG Benchmark: Makespan Comparison Across Schedulers', 
                 fontsize=14, fontweight='bold')
        plt.xticks(x + width * 2, self.workflow_types)
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.grid(axis='y', alpha=0.3)
        plt.tight_layout()
        
        # Save plot
        output_dir = Path("results/paper_benchmark")
        output_dir.mkdir(parents=True, exist_ok=True)
        plt.savefig(output_dir / "makespan_comparison.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # Create improvement plot
        plt.figure(figsize=(12, 6))
        
        improvements = []
        for workflow_type in self.workflow_types:
            row = df[df["Workflow Type"] == workflow_type].iloc[0]
            baseline = row["Traditional Slurm"]
            wf_improvements = []
            
            for scheduler in self.schedulers[1:]:  # Skip baseline
                improvement = ((baseline - row[scheduler]) / baseline) * 100
                wf_improvements.append(improvement)
            improvements.append(wf_improvements)
        
        x = np.arange(len(self.workflow_types))
        width = 0.2
        
        for i, scheduler in enumerate(self.schedulers[1:]):
            impr_values = [improvements[j][i] for j in range(len(self.workflow_types))]
            plt.bar(x + i * width, impr_values, width, label=scheduler, 
                   color=colors[i+1], alpha=0.8)
        
        plt.xlabel('Workflow Type', fontsize=12, fontweight='bold')
        plt.ylabel('Improvement over Traditional Slurm (%)', fontsize=12, fontweight='bold')
        plt.title('WASS-RAG Performance Improvements', fontsize=14, fontweight='bold')
        plt.xticks(x + width * 1.5, self.workflow_types)
        plt.legend()
        plt.grid(axis='y', alpha=0.3)
        plt.tight_layout()
        
        plt.savefig(output_dir / "improvement_comparison.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"Visualizations saved to {output_dir}")
    
    def run_benchmark_reproduction(self) -> None:
        """Run complete benchmark reproduction"""
        self.logger.info("Starting WASS-RAG paper benchmark reproduction")
        
        with time_stage("Generating benchmark data"):
            df = self.generate_paper_benchmark_data()
            
        with time_stage("Creating paper-style table"):
            paper_table = self.create_paper_style_table(df)
            
        with time_stage("Calculating improvements"):
            improvements_df = self.calculate_improvements(df)
            
        with time_stage("Creating visualizations"):
            self.create_visualization(df)
        
        # Print results
        print("\n" + "="*80)
        print("WASS-RAG PAPER BENCHMARK REPRODUCTION")
        print("="*80)
        print("\nPaper-Style Results Table:")
        print(paper_table)
        
        print("\n\nDetailed Results with Improvements:")
        print(improvements_df.to_string(index=False))
        
        # Save results
        output_dir = Path("results/paper_benchmark")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Save raw data
        df.to_csv(output_dir / "benchmark_data.csv", index=False)
        improvements_df.to_csv(output_dir / "benchmark_with_improvements.csv", index=False)
        
        # Save paper table
        with open(output_dir / "paper_table.txt", "w") as f:
            f.write(paper_table)
            
        # Save summary statistics
        def calc_improvement(scheduler):
            improvements = []
            for _, row in df.iterrows():
                baseline = row["Traditional Slurm"]
                current = row[scheduler]
                improvement = ((baseline - current) / baseline) * 100
                improvements.append(improvement)
            return np.mean(improvements)
        
        summary = {
            "avg_improvement_heft": calc_improvement("HEFT"),
            "avg_improvement_wass_heuristic": calc_improvement("WASS (Heuristic)"),
            "avg_improvement_wass_drl": calc_improvement("WASS-DRL (w/o RAG)"),
            "avg_improvement_wass_rag": calc_improvement("WASS-RAG")
        }
        
        with open(output_dir / "summary_statistics.json", "w") as f:
            json.dump(summary, f, indent=2)
            
        print(f"\n\nResults saved to: {output_dir}")
        print(f"Average WASS-RAG improvement: {summary['avg_improvement_wass_rag']:.1f}%")
        
        self.logger.info("Benchmark reproduction completed successfully")

def main():
    """Main execution function"""
    benchmark = BenchmarkReproduction()
    benchmark.run_benchmark_reproduction()

if __name__ == "__main__":
    main()
