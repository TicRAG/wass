"""å·¥å…·å‡½æ•°ã€æ—¥å¿—è®¾ç½®å’Œæœ€ç»ˆç‰ˆçš„å®éªŒè¿è¡Œå™¨ã€‚"""
from __future__ import annotations
import logging
import time
from contextlib import contextmanager
from typing import Dict, Any, Generator, List
from pathlib import Path
import sys
import wrench
import pandas as pd
import numpy as np

def get_logger(name, level=logging.INFO):
    """è·å–ä¸€ä¸ªå·²é…ç½®çš„æ—¥å¿—å™¨ã€‚"""
    logger = logging.getLogger(name)
    logger.setLevel(level)
    if not logger.handlers:
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler = logging.StreamHandler(sys.stdout)
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    return logger

# --- æœ€ç»ˆç‰ˆå®éªŒè¿è¡Œå™¨ ---
class WrenchExperimentRunner:
    """å¤„ç†å¤šä¸ªWRENCHæ¨¡æ‹Ÿçš„æ‰§è¡Œï¼Œä»¥æ¯”è¾ƒä¸åŒçš„è°ƒåº¦å™¨ã€‚"""
    def __init__(self, schedulers: Dict[str, Any], config: Dict[str, Any]):
        self.schedulers_map = schedulers
        self.config = config
        self.platform_file = config.get("platform_file")
        self.workflow_dir = Path(config.get("workflow_dir", "workflows"))
        self.workflow_sizes = config.get("workflow_sizes", [20, 50, 100])
        self.repetitions = config.get("repetitions", 3)
        self.output_dir = Path(config.get("output_dir", "results/final_experiments"))
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def _run_single_simulation(self, scheduler_name: str, scheduler_impl: Any, workflow_file: str) -> Dict[str, Any]:
        """è¿è¡Œå•ä¸ªWRENCHæ¨¡æ‹Ÿå¹¶è¿”å›ç»“æœã€‚"""
        try:
            sim = wrench.Simulation()
            sim.add_platform(self.platform_file)
            
            all_hosts = list(sim.get_platform().get_compute_hosts().keys())
            controller = all_hosts[0]
            compute_hosts = all_hosts[1:] if len(all_hosts) > 1 else all_hosts
            
            cs = wrench.BareMetalComputeService(controller, compute_hosts)
            sim.add_compute_service(cs)

            # å®ä¾‹åŒ–è°ƒåº¦å™¨
            scheduler_instance = scheduler_impl
            if hasattr(scheduler_impl, 'set_simulation_context'):
                 scheduler_instance.set_simulation_context(sim, cs, {h:{} for h in compute_hosts})

            sim.set_scheduler(scheduler_instance)
            workflow = sim.create_workflow_from_json(str(workflow_file))
            job = sim.create_standard_job(workflow.get_tasks())
            cs.submit_job(job)
            sim.run()
            
            return {"scheduler": scheduler_name, "workflow": workflow_file.name, "makespan": sim.get_makespan(), "status": "success"}
        except Exception as e:
            print(f"ERROR running {scheduler_name} on {workflow_file.name}: {e}")
            return {"scheduler": scheduler_name, "workflow": workflow_file.name, "makespan": float('inf'), "status": "failed"}

    def run_all(self) -> List[Dict[str, Any]]:
        """è¿è¡Œæ‰€æœ‰é…ç½®çš„å®éªŒã€‚"""
        results = []
        total_exps = len(self.schedulers_map) * len(self.workflow_sizes) * self.repetitions
        print(f"æ€»å®éªŒæ•°: {total_exps}")
        
        exp_count = 0
        for name, sched_impl in self.schedulers_map.items():
            for size in self.workflow_sizes:
                # [FIX] æ™ºèƒ½æ‰«æå·¥ä½œæµæ–‡ä»¶ï¼Œè€Œä¸æ˜¯ä¾èµ–å›ºå®šåç§°
                matching_files = list(self.workflow_dir.glob(f'*_{size}_*.json')) + \
                                 list(self.workflow_dir.glob(f'*_{size}.json')) + \
                                 list(self.workflow_dir.glob(f'*{size}-tasks-wf.json'))
                
                if not matching_files:
                    print(f"[è­¦å‘Š] åœ¨ {self.workflow_dir} ä¸­æœªæ‰¾åˆ°å¤§å°ä¸º {size} çš„å·¥ä½œæµæ–‡ä»¶ï¼Œè·³è¿‡...")
                    continue
                
                # ä¸ºäº†å®éªŒçš„ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬åªä½¿ç”¨æ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªåŒ¹é…æ–‡ä»¶
                workflow_file_to_run = matching_files[0]
                
                for rep in range(self.repetitions):
                    exp_count += 1
                    print(f"è¿è¡Œå®éªŒ [{exp_count}/{total_exps}]: {name} on {workflow_file_to_run.name}")
                    result = self._run_single_simulation(name, sched_impl, workflow_file_to_run)
                    results.append(result)
        return results

    def analyze_results(self, results: List[Dict[str, Any]]):
        """åˆ†æã€æ‰“å°å¹¶ä¿å­˜å®éªŒç»“æœæ‘˜è¦ã€‚"""
        if not results:
            print("æ²¡æœ‰å¯ä¾›åˆ†æçš„å®éªŒç»“æœã€‚"); return

        df = pd.DataFrame(results)
        
        # ä¿å­˜è¯¦ç»†çš„åŸå§‹ç»“æœ
        detailed_csv_path = self.output_dir / "detailed_results.csv"
        df.to_csv(detailed_csv_path, index=False)
        print(f"âœ… è¯¦ç»†å®éªŒç»“æœå·²ä¿å­˜åˆ°: {detailed_csv_path}")

        summary = df.groupby('scheduler')['makespan'].agg(['mean', 'std', 'min', 'count']).reset_index()
        summary = summary.rename(columns={'scheduler': 'è°ƒåº¦å™¨', 'mean': 'å¹³å‡Makespan', 'std': 'æ ‡å‡†å·®', 'min': 'æœ€ä½³', 'count': 'å®éªŒæ¬¡æ•°'})

        print("\n" + "="*60); print("ğŸ“ˆ å®éªŒç»“æœåˆ†æ:"); print(summary.to_string(index=False)); print("="*60 + "\n")
        
        # [FIX] ä¿å­˜æœ€ç»ˆçš„æ‘˜è¦ç»“æœ
        summary_csv_path = self.output_dir / "summary_results.csv"
        summary.to_csv(summary_csv_path, index=False)
        print(f"âœ… å®éªŒç»“æœæ‘˜è¦å·²ä¿å­˜åˆ°: {summary_csv_path}")