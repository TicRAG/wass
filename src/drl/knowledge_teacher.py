# src/drl/knowledge_teacher.py
import faiss
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from pathlib import Path

class KnowledgeBase:
    """
    å°è£…FAISSå‘é‡ç´¢å¼•å’Œå…ƒæ•°æ®çš„çŸ¥è¯†åº“ã€‚
    """
    def __init__(self, dimension: int, storage_path: str = "data/knowledge_base"):
        self.dimension = dimension
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)
        
        self.index_file = self.storage_path / "workflow_embeddings.index"
        self.meta_file = self.storage_path / "workflow_metadata.csv"
        
        # åˆå§‹åŒ–æˆ–åŠ è½½
        if self.index_file.exists() and self.meta_file.exists():
            print("ğŸ§  [Teacher] Loading existing Knowledge Base...")
            self.index = faiss.read_index(str(self.index_file))
            self.metadata = pd.read_csv(self.meta_file)
            print("âœ… [Teacher] Knowledge Base loaded.")
        else:
            print("âš ï¸ [Teacher] No existing Knowledge Base found. Initializing a new one.")
            self.index = faiss.IndexFlatL2(dimension)
            self.metadata = pd.DataFrame()

    def add(self, vectors: np.ndarray, metadata_list: list[dict]):
        """å‘çŸ¥è¯†åº“ä¸­æ·»åŠ æ–°çš„ç»éªŒè½¨è¿¹"""
        if not hasattr(vectors, 'shape') or vectors.shape[0] == 0:
            print("âš ï¸ [KB] Attempted to add empty vectors. Skipping.")
            return
            
        vectors = np.ascontiguousarray(vectors, dtype=np.float32)
        self.index.add(vectors)
        new_metadata = pd.DataFrame(metadata_list)
        self.metadata = pd.concat([self.metadata, new_metadata], ignore_index=True)

    def search(self, query_vector: np.ndarray, k: int = 5) -> pd.DataFrame:
        """æ£€ç´¢ä¸æŸ¥è¯¢å‘é‡æœ€ç›¸ä¼¼çš„kä¸ªæ¡ˆä¾‹"""
        if self.index.ntotal == 0:
            return pd.DataFrame() # å¦‚æœçŸ¥è¯†åº“ä¸ºç©ºï¼Œè¿”å›ç©ºçš„DataFrame

        query_vector = np.ascontiguousarray(query_vector.reshape(1, -1), dtype=np.float32)
        distances, indices = self.index.search(query_vector, k)
        
        # è¿‡æ»¤æ‰æ— æ•ˆçš„ç´¢å¼• (-1)
        valid_indices = indices[0][indices[0] != -1]
        if len(valid_indices) == 0:
            return pd.DataFrame()
            
        return self.metadata.iloc[valid_indices]

    def save(self):
        """ä¿å­˜çŸ¥è¯†åº“åˆ°ç£ç›˜"""
        print(f"ğŸ’¾ [KB] Saving Knowledge Base with {self.index.ntotal} entries...")
        faiss.write_index(self.index, str(self.index_file))
        self.metadata.to_csv(self.meta_file, index=False)
        print("âœ… [KB] Knowledge Base saved.")


class PerformancePredictor(nn.Module):
    """ä¸€ä¸ªç®€å•çš„MLPï¼Œè¾“å…¥æ˜¯æ‰‹å·¥è®¾è®¡çš„ç»Ÿè®¡ç‰¹å¾ã€‚"""
    def __init__(self, input_dim: int):
        super(PerformancePredictor, self).__init__()
        # ä¸ train_predictor.py ä¸­çš„ SimplePredictor ç»“æ„ä¿æŒä¸€è‡´
        self.model = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )

    def forward(self, x):
        return self.model(x)

class KnowledgeableTeacher:
    """
    çŸ¥è¯†å¼•å¯¼æ•™å¸ˆï¼Œè´Ÿè´£ç”ŸæˆRAGå¥–åŠ±ã€‚
    """
    def __init__(self, state_dim: int, knowledge_base: KnowledgeBase):
        self.kb = knowledge_base
        # æ³¨æ„ï¼šè¿™é‡Œçš„è¾“å…¥ç»´åº¦åº”è¯¥ä¸ state_embedding çš„ç»´åº¦ä¸€è‡´
        self.predictor = PerformancePredictor(input_dim=state_dim)
        
        # åŠ è½½é¢„è®­ç»ƒçš„æ€§èƒ½é¢„æµ‹å™¨æ¨¡å‹
        # æ³¨æ„ï¼šè¿™é‡Œçš„æ¨¡å‹æ˜¯ç”¨äºGNNè¾“å‡ºçš„ï¼Œè€Œä¸æ˜¯train_predictor.pyä¸­çš„ç»Ÿè®¡ç‰¹å¾æ¨¡å‹
        # æˆ‘ä»¬æš‚æ—¶å‡è®¾æœ‰ä¸€ä¸ªé¢„è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰ï¼Œå®ƒå°†ä»¥éšæœºæƒé‡å¼€å§‹
        predictor_model_path = "models/saved_models/performance_predictor.pth"
        try:
            # æ³¨æ„ï¼šè¿™é‡Œçš„åŠ è½½é€»è¾‘å¯èƒ½éœ€è¦æ ¹æ®å®é™…ä¿å­˜çš„æ¨¡å‹ç»“æ„è°ƒæ•´
            # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„ç¤ºä¾‹
            # self.predictor.load_state_dict(torch.load(predictor_model_path))
            # self.predictor.eval()
            print("âœ… [Teacher] Performance predictor structure initialized.")
            print("âš ï¸ [Teacher] Note: Predictor is using initial random weights as it needs separate training.")
        except Exception as e:
            print(f"âŒ [Teacher] Could not load performance predictor model: {e}. Using random weights.")


    def generate_rag_reward(self, state_embedding: torch.Tensor, current_action: int) -> float:
        """
        ç”ŸæˆRAGå¥–åŠ± (æ”¹è¿›ç‰ˆ)ã€‚
        å¥–åŠ± = (æ£€ç´¢åˆ°çš„å†å²æ¡ˆä¾‹çš„å¹³å‡æ€§èƒ½ - é¢„æµ‹çš„å½“å‰åŠ¨ä½œæ€§èƒ½)
        """
        # 1. æ£€ç´¢ç›¸ä¼¼æ¡ˆä¾‹
        # detach().numpy() å°†å…¶ä»è®¡ç®—å›¾ä¸­åˆ†ç¦»å¹¶è½¬æ¢ä¸ºnumpyæ•°ç»„
        similar_cases = self.kb.search(state_embedding.detach().cpu().numpy(), k=5)
        
        if similar_cases.empty or 'makespan' not in similar_cases.columns:
            return 0.0 # å¦‚æœæ²¡æœ‰ç›¸ä¼¼æ¡ˆä¾‹ï¼Œä¸æä¾›å¥–åŠ±

        # 2. ä»å…ƒæ•°æ®ä¸­è·å–å†å²æ€§èƒ½
        historical_makespans = similar_cases['makespan'].values
        
        # 3. è®¡ç®—å¥–åŠ±
        # å¥–åŠ±æ ¸å¿ƒæ€æƒ³ï¼šå¦‚æœå†å²æœ€ä¼˜åšæ³•æ¯”å¹³å‡å¥½å¾ˆå¤šï¼Œé‚£ä¹ˆè¿™æ˜¯ä¸€ä¸ªå€¼å¾—æ¢ç´¢çš„æ–¹å‘
        # æˆ‘ä»¬ç»™äºˆæ­£å¥–åŠ±ï¼Œé¼“åŠ±æ™ºèƒ½ä½“å­¦ä¹ è¿™ç§æ¨¡å¼
        # å½’ä¸€åŒ–å¥–åŠ±å€¼ï¼Œä½¿å…¶å¤§å°æ›´ç¨³å®š
        mean_perf = np.mean(historical_makespans)
        best_perf = np.min(historical_makespans)
        
        if mean_perf > 0:
            reward = (mean_perf - best_perf) / mean_perf
        else:
            reward = 0.0
        
        # è¿”å›ä¸€ä¸ªè¾ƒå°çš„ã€ç¨³å®šçš„æ­£å¥–åŠ±
        return float(reward)