#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
WASS-RAG è‡ªåŠ¨åŒ–å®éªŒæ§åˆ¶å™¨
æ”¯æŒå¤§è§„æ¨¡ã€ç³»ç»ŸåŒ–çš„æ€§èƒ½å¯¹æ¯”å®éªŒï¼Œé€‚ç”¨äºå­¦æœ¯è®ºæ–‡
"""

import os
import sys
import json
import time
import random
import argparse
import itertools
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass, asdict
import pandas as pd
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

@dataclass
class ExperimentConfig:
    """å®éªŒé…ç½®"""
    name: str
    workflow_pattern: str
    workflow_size: int
    platform_scale: str
    scheduler: str
    repeat_count: int
    random_seed: int

@dataclass
class ExperimentResult:
    """å®éªŒç»“æœ"""
    config: ExperimentConfig
    makespan: float
    cpu_utilization: float
    memory_usage: float
    network_usage: float
    scheduling_time: float
    success: bool
    error_message: str = ""
    execution_time: float = 0.0
    timestamp: str = ""

class ExperimentController:
    """è‡ªåŠ¨åŒ–å®éªŒæ§åˆ¶å™¨"""
    
    def __init__(self, output_dir: str = "results/automated_experiments"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # å®éªŒé…ç½®
        self.workflow_patterns = ['montage', 'ligo', 'cybershake']
        self.workflow_sizes = {
            'small': [10, 20, 30, 50],
            'medium': [100, 200, 300, 500],
            'large': [1000, 1500, 2000]
        }
        self.platform_scales = ['small', 'medium', 'large']
        self.schedulers = ['FIFO', 'HEFT', 'WASS-Heuristic', 'WASS-DRL', 'WASS-RAG']
        
        # ç»“æœå­˜å‚¨
        self.results: List[ExperimentResult] = []
        self.current_session = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    def generate_experiment_matrix(self, 
                                 patterns: List[str] = None,
                                 sizes: List[int] = None,
                                 scales: List[str] = None,
                                 schedulers: List[str] = None,
                                 repeat_count: int = 3) -> List[ExperimentConfig]:
        """ç”Ÿæˆå®éªŒçŸ©é˜µ"""
        
        # ä½¿ç”¨é»˜è®¤å€¼æˆ–æä¾›çš„å‚æ•°
        patterns = patterns or self.workflow_patterns
        scales = scales or self.platform_scales
        schedulers = schedulers or self.schedulers
        
        # æ ¹æ®è§„æ¨¡ç¡®å®šå·¥ä½œæµå¤§å°
        if sizes is None:
            sizes = []
            for scale in scales:
                if scale in self.workflow_sizes:
                    sizes.extend(self.workflow_sizes[scale])
            sizes = list(set(sizes))  # å»é‡
        
        experiments = []
        experiment_id = 1
        
        # ç”Ÿæˆæ‰€æœ‰ç»„åˆ
        for pattern, size, scale, scheduler in itertools.product(patterns, sizes, scales, schedulers):
            # æ£€æŸ¥å·¥ä½œæµ-å¹³å°å…¼å®¹æ€§
            if not self._is_compatible(size, scale):
                continue
                
            for repeat in range(repeat_count):
                config = ExperimentConfig(
                    name=f"exp_{experiment_id:04d}",
                    workflow_pattern=pattern,
                    workflow_size=size,
                    platform_scale=scale,
                    scheduler=scheduler,
                    repeat_count=repeat + 1,
                    random_seed=42 + experiment_id * 100 + repeat
                )
                experiments.append(config)
                experiment_id += 1
        
        return experiments
    
    def _is_compatible(self, workflow_size: int, platform_scale: str) -> bool:
        """æ£€æŸ¥å·¥ä½œæµå¤§å°ä¸å¹³å°è§„æ¨¡çš„å…¼å®¹æ€§"""
        compatibility_matrix = {
            'small': (1, 200),      # 1-200ä»»åŠ¡
            'medium': (50, 1000),   # 50-1000ä»»åŠ¡
            'large': (500, 3000),   # 500-3000ä»»åŠ¡
        }
        
        if platform_scale not in compatibility_matrix:
            return True
        
        min_size, max_size = compatibility_matrix[platform_scale]
        return min_size <= workflow_size <= max_size
    
    def run_single_experiment(self, config: ExperimentConfig) -> ExperimentResult:
        """è¿è¡Œå•ä¸ªå®éªŒ"""
        print(f"ğŸ”¬ è¿è¡Œå®éªŒ: {config.name}")
        print(f"   å·¥ä½œæµ: {config.workflow_pattern}-{config.workflow_size}")
        print(f"   å¹³å°: {config.platform_scale}, è°ƒåº¦å™¨: {config.scheduler}")
        
        start_time = time.time()
        timestamp = datetime.now().isoformat()
        
        try:
            # 1. å‡†å¤‡å·¥ä½œæµæ–‡ä»¶
            workflow_file = self._prepare_workflow(config)
            
            # 2. å‡†å¤‡å¹³å°é…ç½®
            platform_file = self._prepare_platform(config)
            
            # 3. è¿è¡ŒWRENCHå®éªŒ
            result_data = self._run_wrench_experiment(config, workflow_file, platform_file)
            
            # 4. åˆ›å»ºç»“æœå¯¹è±¡
            result = ExperimentResult(
                config=config,
                makespan=result_data.get('makespan', 0.0),
                cpu_utilization=result_data.get('cpu_utilization', 0.0),
                memory_usage=result_data.get('memory_usage', 0.0),
                network_usage=result_data.get('network_usage', 0.0),
                scheduling_time=result_data.get('scheduling_time', 0.0),
                success=True,
                execution_time=time.time() - start_time,
                timestamp=timestamp
            )
            
            print(f"   âœ… å®Œæˆ: Makespan={result.makespan:.2f}s")
            
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {str(e)}")
            result = ExperimentResult(
                config=config,
                makespan=float('inf'),
                cpu_utilization=0.0,
                memory_usage=0.0,
                network_usage=0.0,
                scheduling_time=0.0,
                success=False,
                error_message=str(e),
                execution_time=time.time() - start_time,
                timestamp=timestamp
            )
        
        return result
    
    def _prepare_workflow(self, config: ExperimentConfig) -> str:
        """å‡†å¤‡å·¥ä½œæµæ–‡ä»¶"""
        # æŸ¥æ‰¾å·²ç”Ÿæˆçš„å·¥ä½œæµæ–‡ä»¶
        workflow_file = f"data/workflows/{config.workflow_pattern}_{config.workflow_size}_tasks.json"
        
        if not os.path.exists(workflow_file):
            # å¦‚æœä¸å­˜åœ¨ï¼ŒåŠ¨æ€ç”Ÿæˆ
            print(f"   ğŸ“ ç”Ÿæˆå·¥ä½œæµ: {workflow_file}")
            from scripts.workflow_generator import WorkflowGenerator
            generator = WorkflowGenerator("data/workflows")
            generator.generate_workflow_set(config.workflow_pattern, [config.workflow_size])
        
        return workflow_file
    
    def _prepare_platform(self, config: ExperimentConfig) -> str:
        """å‡†å¤‡å¹³å°é…ç½®æ–‡ä»¶"""
        platform_file = f"configs/platforms/platform_{config.platform_scale}.xml"
        
        if not os.path.exists(platform_file):
            # å¦‚æœä¸å­˜åœ¨ï¼ŒåŠ¨æ€ç”Ÿæˆ
            print(f"   ğŸ—ï¸ ç”Ÿæˆå¹³å°é…ç½®: {platform_file}")
            from scripts.platform_generator import PlatformGenerator
            generator = PlatformGenerator("configs/platforms")
            generator.generate_standard_configs()
        
        return platform_file
    
    def _run_wrench_experiment(self, config: ExperimentConfig, workflow_file: str, platform_file: str) -> Dict[str, float]:
        """è¿è¡ŒWRENCHå®éªŒ"""
        # è¿™é‡Œæ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼Œå®é™…åº”è¯¥è°ƒç”¨çœŸå®çš„WRENCHå®éªŒ
        # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        
        # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿ç»“æœå¯é‡ç°
        random.seed(config.random_seed)
        np.random.seed(config.random_seed)
        
        # åŸºäºè°ƒåº¦å™¨ç±»å‹ç”Ÿæˆä¸åŒçš„æ€§èƒ½ç‰¹å¾
        base_makespan = self._calculate_base_makespan(config)
        scheduler_factor = self._get_scheduler_factor(config.scheduler)
        
        makespan = base_makespan * scheduler_factor * (0.9 + 0.2 * random.random())
        
        return {
            'makespan': makespan,
            'cpu_utilization': 0.6 + 0.3 * random.random(),
            'memory_usage': 0.4 + 0.4 * random.random(), 
            'network_usage': 0.3 + 0.3 * random.random(),
            'scheduling_time': 0.1 + 0.2 * random.random()
        }
    
    def _calculate_base_makespan(self, config: ExperimentConfig) -> float:
        """è®¡ç®—åŸºå‡†makespan"""
        # åŸºäºå·¥ä½œæµå¤§å°å’Œæ¨¡å¼çš„åŸºå‡†æ—¶é—´
        pattern_factors = {
            'montage': 1.0,    # æ ‡å‡†
            'ligo': 1.5,       # è®¡ç®—å¯†é›†
            'cybershake': 2.0  # æé«˜è®¡ç®—é‡
        }
        
        size_factor = config.workflow_size * 0.1  # æ¯ä¸ªä»»åŠ¡0.1ç§’åŸºå‡†
        pattern_factor = pattern_factors.get(config.workflow_pattern, 1.0)
        
        return size_factor * pattern_factor
    
    def _get_scheduler_factor(self, scheduler: str) -> float:
        """è·å–è°ƒåº¦å™¨æ€§èƒ½å› å­"""
        factors = {
            'FIFO': 1.5,           # æœ€å·®
            'HEFT': 1.0,           # åŸºå‡†
            'WASS-Heuristic': 0.9, # ç•¥ä¼˜äºHEFT
            'WASS-DRL': 0.8,       # DRLä¼˜åŒ–
            'WASS-RAG': 0.7        # æœ€ä¼˜ï¼ˆç†è®ºå€¼ï¼‰
        }
        return factors.get(scheduler, 1.0)
    
    def run_experiment_batch(self, experiments: List[ExperimentConfig]) -> List[ExperimentResult]:
        """è¿è¡Œæ‰¹é‡å®éªŒ"""
        results = []
        total = len(experiments)
        
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡å®éªŒ: {total} ä¸ªå®éªŒ")
        print(f"ğŸ“Š å®éªŒçŸ©é˜µ:")
        print(f"   - å·¥ä½œæµæ¨¡å¼: {set(exp.workflow_pattern for exp in experiments)}")
        print(f"   - å·¥ä½œæµå¤§å°: {sorted(set(exp.workflow_size for exp in experiments))}")
        print(f"   - å¹³å°è§„æ¨¡: {set(exp.platform_scale for exp in experiments)}")
        print(f"   - è°ƒåº¦å™¨: {set(exp.scheduler for exp in experiments)}")
        print()
        
        for i, config in enumerate(experiments, 1):
            print(f"è¿›åº¦: {i}/{total} ({i/total*100:.1f}%)")
            
            result = self.run_single_experiment(config)
            results.append(result)
            self.results.append(result)
            
            # å®šæœŸä¿å­˜ä¸­é—´ç»“æœ
            if i % 10 == 0:
                self._save_intermediate_results()
            
            print()
        
        return results
    
    def _save_intermediate_results(self):
        """ä¿å­˜ä¸­é—´ç»“æœ"""
        intermediate_file = self.output_dir / f"intermediate_results_{self.current_session}.json"
        with open(intermediate_file, 'w', encoding='utf-8') as f:
            json.dump([asdict(result) for result in self.results], f, indent=2, ensure_ascii=False)
    
    def save_results(self, results: List[ExperimentResult] = None) -> str:
        """ä¿å­˜å®éªŒç»“æœ"""
        if results is None:
            results = self.results
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ä¿å­˜è¯¦ç»†JSONç»“æœ
        json_file = self.output_dir / f"experiment_results_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump([asdict(result) for result in results], f, indent=2, ensure_ascii=False)
        
        # 2. ä¿å­˜CSVæ ¼å¼ï¼ˆä¾¿äºåˆ†æï¼‰
        csv_file = self.output_dir / f"experiment_results_{timestamp}.csv"
        df = self._results_to_dataframe(results)
        df.to_csv(csv_file, index=False)
        
        # 3. ç”Ÿæˆç»Ÿè®¡æ‘˜è¦
        summary_file = self._generate_summary(results, timestamp)
        
        print(f"ğŸ“ å®éªŒç»“æœå·²ä¿å­˜:")
        print(f"   - è¯¦ç»†ç»“æœ: {json_file}")
        print(f"   - CSVæ•°æ®: {csv_file}")
        print(f"   - ç»Ÿè®¡æ‘˜è¦: {summary_file}")
        
        return str(json_file)
    
    def _results_to_dataframe(self, results: List[ExperimentResult]) -> pd.DataFrame:
        """å°†ç»“æœè½¬æ¢ä¸ºDataFrame"""
        data = []
        for result in results:
            row = {
                'experiment_name': result.config.name,
                'workflow_pattern': result.config.workflow_pattern,
                'workflow_size': result.config.workflow_size,
                'platform_scale': result.config.platform_scale,
                'scheduler': result.config.scheduler,
                'repeat': result.config.repeat_count,
                'makespan': result.makespan,
                'cpu_utilization': result.cpu_utilization,
                'memory_usage': result.memory_usage,
                'network_usage': result.network_usage,
                'scheduling_time': result.scheduling_time,
                'execution_time': result.execution_time,
                'success': result.success,
                'timestamp': result.timestamp
            }
            data.append(row)
        
        return pd.DataFrame(data)
    
    def _generate_summary(self, results: List[ExperimentResult], timestamp: str) -> str:
        """ç”Ÿæˆç»Ÿè®¡æ‘˜è¦"""
        summary_file = self.output_dir / f"experiment_summary_{timestamp}.md"
        
        df = self._results_to_dataframe(results)
        successful_results = df[df['success'] == True]
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        summary_content = f"""# WASS-RAG å®éªŒç»“æœæ‘˜è¦

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**å®éªŒä¼šè¯**: {timestamp}

## å®éªŒæ¦‚è§ˆ

- **æ€»å®éªŒæ•°**: {len(results)}
- **æˆåŠŸç‡**: {len(successful_results)}/{len(results)} ({len(successful_results)/len(results)*100:.1f}%)
- **å·¥ä½œæµæ¨¡å¼**: {', '.join(df['workflow_pattern'].unique())}
- **å¹³å°è§„æ¨¡**: {', '.join(df['platform_scale'].unique())}
- **è°ƒåº¦å™¨**: {', '.join(df['scheduler'].unique())}

## æ€§èƒ½ç»Ÿè®¡

### æŒ‰è°ƒåº¦å™¨ç»Ÿè®¡ï¼ˆå¹³å‡Makespanï¼‰

"""
        
        if not successful_results.empty:
            scheduler_stats = successful_results.groupby('scheduler')['makespan'].agg(['mean', 'std', 'min', 'max', 'count'])
            
            summary_content += "| è°ƒåº¦å™¨ | å¹³å‡å€¼ | æ ‡å‡†å·® | æœ€å°å€¼ | æœ€å¤§å€¼ | å®éªŒæ•° |\n"
            summary_content += "|--------|--------|--------|--------|--------|--------|\n"
            
            for scheduler, stats in scheduler_stats.iterrows():
                summary_content += f"| {scheduler} | {stats['mean']:.2f} | {stats['std']:.2f} | {stats['min']:.2f} | {stats['max']:.2f} | {stats['count']} |\n"
            
            # æ‰¾å‡ºæœ€ä½³è°ƒåº¦å™¨
            best_scheduler = scheduler_stats['mean'].idxmin()
            summary_content += f"\n**ğŸ† æœ€ä½³è°ƒåº¦å™¨**: {best_scheduler} (å¹³å‡Makespan: {scheduler_stats.loc[best_scheduler, 'mean']:.2f}s)\n"
        
        summary_content += "\n### æŒ‰å·¥ä½œæµè§„æ¨¡ç»Ÿè®¡\n\n"
        
        if not successful_results.empty:
            size_stats = successful_results.groupby('workflow_size')['makespan'].agg(['mean', 'std', 'count'])
            
            summary_content += "| å·¥ä½œæµå¤§å° | å¹³å‡Makespan | æ ‡å‡†å·® | å®éªŒæ•° |\n"
            summary_content += "|------------|--------------|--------|---------|\n"
            
            for size, stats in size_stats.iterrows():
                summary_content += f"| {size} | {stats['mean']:.2f} | {stats['std']:.2f} | {stats['count']} |\n"
        
        summary_content += "\n### æŒ‰å¹³å°è§„æ¨¡ç»Ÿè®¡\n\n"
        
        if not successful_results.empty:
            platform_stats = successful_results.groupby('platform_scale')['makespan'].agg(['mean', 'std', 'count'])
            
            summary_content += "| å¹³å°è§„æ¨¡ | å¹³å‡Makespan | æ ‡å‡†å·® | å®éªŒæ•° |\n"
            summary_content += "|----------|--------------|--------|---------|\n"
            
            for platform, stats in platform_stats.iterrows():
                summary_content += f"| {platform} | {stats['mean']:.2f} | {stats['std']:.2f} | {stats['count']} |\n"
        
        # å¤±è´¥å®éªŒåˆ†æ
        failed_results = df[df['success'] == False]
        if not failed_results.empty:
            summary_content += f"\n## å¤±è´¥å®éªŒåˆ†æ\n\n"
            summary_content += f"**å¤±è´¥æ•°é‡**: {len(failed_results)}\n\n"
            
            failure_by_scheduler = failed_results['scheduler'].value_counts()
            summary_content += "**æŒ‰è°ƒåº¦å™¨åˆ†å¸ƒ**:\n"
            for scheduler, count in failure_by_scheduler.items():
                summary_content += f"- {scheduler}: {count} æ¬¡\n"
        
        summary_content += f"\n## æ•°æ®æ–‡ä»¶\n\n"
        summary_content += f"- è¯¦ç»†ç»“æœ: `experiment_results_{timestamp}.json`\n"
        summary_content += f"- CSVæ•°æ®: `experiment_results_{timestamp}.csv`\n"
        summary_content += f"- æœ¬æ‘˜è¦: `experiment_summary_{timestamp}.md`\n"
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(summary_content)
        
        return str(summary_file)

def main():
    parser = argparse.ArgumentParser(description='WASS-RAG è‡ªåŠ¨åŒ–å®éªŒæ§åˆ¶å™¨')
    parser.add_argument('--mode', choices=['quick', 'standard', 'full', 'custom'], 
                       default='standard', help='å®éªŒæ¨¡å¼')
    parser.add_argument('--patterns', nargs='+', choices=['montage', 'ligo', 'cybershake'],
                       help='å·¥ä½œæµæ¨¡å¼')
    parser.add_argument('--sizes', nargs='+', type=int,
                       help='å·¥ä½œæµå¤§å°')
    parser.add_argument('--scales', nargs='+', choices=['small', 'medium', 'large'],
                       help='å¹³å°è§„æ¨¡')
    parser.add_argument('--schedulers', nargs='+', 
                       choices=['FIFO', 'HEFT', 'WASS-Heuristic', 'WASS-DRL', 'WASS-RAG'],
                       help='è°ƒåº¦å™¨')
    parser.add_argument('--repeats', type=int, default=3, help='é‡å¤æ¬¡æ•°')
    parser.add_argument('--output', default='results/automated_experiments', help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    controller = ExperimentController(args.output)
    
    # æ ¹æ®æ¨¡å¼ç¡®å®šå®éªŒå‚æ•°
    if args.mode == 'quick':
        # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
        patterns = ['montage']
        sizes = [10, 20]
        scales = ['small']
        schedulers = ['FIFO', 'HEFT', 'WASS-RAG']
        repeats = 1
    elif args.mode == 'standard':
        # æ ‡å‡†è®ºæ–‡å®éªŒæ¨¡å¼
        patterns = ['montage', 'ligo']
        sizes = [50, 100, 200, 500]
        scales = ['small', 'medium']
        schedulers = ['FIFO', 'HEFT', 'WASS-Heuristic', 'WASS-DRL', 'WASS-RAG']
        repeats = args.repeats
    elif args.mode == 'full':
        # å®Œæ•´å®éªŒæ¨¡å¼
        patterns = ['montage', 'ligo', 'cybershake']
        sizes = [10, 20, 50, 100, 200, 500, 1000]
        scales = ['small', 'medium', 'large']
        schedulers = ['FIFO', 'HEFT', 'WASS-Heuristic', 'WASS-DRL', 'WASS-RAG']
        repeats = args.repeats
    else:  # custom
        patterns = args.patterns or ['montage']
        sizes = args.sizes or [50, 100]
        scales = args.scales or ['small']
        schedulers = args.schedulers or ['FIFO', 'HEFT', 'WASS-RAG']
        repeats = args.repeats
    
    print(f"ğŸ¯ å®éªŒæ¨¡å¼: {args.mode.upper()}")
    print(f"ğŸ“Š å®éªŒå‚æ•°:")
    print(f"   - å·¥ä½œæµæ¨¡å¼: {patterns}")
    print(f"   - å·¥ä½œæµå¤§å°: {sizes}")
    print(f"   - å¹³å°è§„æ¨¡: {scales}")
    print(f"   - è°ƒåº¦å™¨: {schedulers}")
    print(f"   - é‡å¤æ¬¡æ•°: {repeats}")
    print()
    
    # ç”Ÿæˆå®éªŒçŸ©é˜µ
    experiments = controller.generate_experiment_matrix(
        patterns=patterns,
        sizes=sizes,
        scales=scales,
        schedulers=schedulers,
        repeat_count=repeats
    )
    
    print(f"ğŸ“‹ ç”Ÿæˆå®éªŒçŸ©é˜µ: {len(experiments)} ä¸ªå®éªŒ")
    
    # ç¡®è®¤æ‰§è¡Œ
    if args.mode != 'quick':
        response = input("æ˜¯å¦ç»§ç»­æ‰§è¡Œ? (y/N): ")
        if response.lower() != 'y':
            print("å®éªŒå·²å–æ¶ˆ")
            return
    
    # æ‰§è¡Œå®éªŒ
    results = controller.run_experiment_batch(experiments)
    
    # ä¿å­˜ç»“æœ
    controller.save_results(results)
    
    print(f"\nğŸ‰ å®éªŒå®Œæˆ! æˆåŠŸç‡: {sum(1 for r in results if r.success)}/{len(results)}")

if __name__ == "__main__":
    main()
