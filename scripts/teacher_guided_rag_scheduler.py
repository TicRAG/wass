#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ”¹è¿›çš„WASS-RAGè°ƒåº¦å™¨ï¼Œæ›´å¥½åœ°èåˆæ•™å¸ˆçŸ¥è¯†å’ŒDRLå†³ç­–
"""

import os
import sys
import json
import time
import random
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
import yaml

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

from src.knowledge_base.wrench_full_kb import WRENCHRAGKnowledgeBase
from src.wrench_schedulers import HEFTScheduler, WassHeuristicScheduler
from src.drl.reward import compute_step_reward, compute_final_reward, StepContext, EpisodeStats

class TeacherGuidedRAGScheduler:
    """æ•™å¸ˆå¼•å¯¼çš„RAGè°ƒåº¦å™¨"""
    
    def __init__(self, config_path: str):
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
        
        self.rag_cfg = self.config.get('rag', {})
        self.drl_cfg = self.config.get('drl', {})
        
        # åŠ è½½çŸ¥è¯†åº“
        kb_path = self.rag_cfg.get('knowledge_base_path', 'src/knowledge_base/wrench_teacher_guided_kb.json')
        self.knowledge_base = WRENCHRAGKnowledgeBase.load(kb_path)
        
        # èåˆæƒé‡ï¼ˆåŠ¨æ€è°ƒæ•´ï¼‰
        self.drl_weight = 0.3  # DRLå†³ç­–æƒé‡
        self.rag_weight = 0.4  # RAGå»ºè®®æƒé‡
        self.teacher_weight = 0.3  # æ•™å¸ˆå»ºè®®æƒé‡
        
        # è‡ªé€‚åº”å‚æ•°
        self.confidence_threshold = 0.7  # ç½®ä¿¡åº¦é˜ˆå€¼
        self.adaptation_rate = 0.01  # è‡ªé€‚åº”å­¦ä¹ ç‡
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_history = []
        self.decision_history = []
        
        # è®¾å¤‡
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    def extract_workflow_features(self, workflow):
        """æå–å·¥ä½œæµç‰¹å¾"""
        tasks = workflow.get_tasks()
        
        features = {
            'num_tasks': len(tasks),
            'avg_task_size': np.mean([task.get_flops() for task in tasks]),
            'max_task_size': max([task.get_flops() for task in tasks]),
            'min_task_size': min([task.get_flops() for task in tasks]),
            'task_size_std': np.std([task.get_flops() for task in tasks]),
            'avg_dependencies': np.mean([len(task.get_parents()) for task in tasks]),
            'max_dependencies': max([len(task.get_parents()) for task in tasks]),
            'critical_path_length': self._estimate_critical_path_length(tasks),
            'parallelism_degree': self._estimate_parallelism_degree(tasks)
        }
        
        return features
    
    def extract_task_features(self, task):
        """æå–ä»»åŠ¡ç‰¹å¾"""
        return {
            'flops': task.get_flops(),
            'num_parents': len(task.get_parents()),
            'num_children': len(task.get_children()),
            'is_entry': len(task.get_parents()) == 0,
            'is_exit': len(task.get_children()) == 0
        }
    
    def _estimate_critical_path_length(self, tasks):
        """ä¼°è®¡å…³é”®è·¯å¾„é•¿åº¦"""
        task_depths = {}
        
        # åˆå§‹åŒ–å…¥å£ä»»åŠ¡
        for task in tasks:
            if len(task.get_parents()) == 0:
                task_depths[task] = 1
        
        # åŠ¨æ€è§„åˆ’è®¡ç®—æ·±åº¦
        changed = True
        while changed:
            changed = False
            for task in tasks:
                if task not in task_depths and all(parent in task_depths for parent in task.get_parents()):
                    parent_depths = [task_depths[parent] for parent in task.get_parents()]
                    task_depths[task] = max(parent_depths) + 1
                    changed = True
        
        return max(task_depths.values()) if task_depths else 1
    
    def _estimate_parallelism_degree(self, tasks):
        """ä¼°è®¡å¹¶è¡Œåº¦"""
        task_depths = {}
        
        # åˆå§‹åŒ–å…¥å£ä»»åŠ¡
        for task in tasks:
            if len(task.get_parents()) == 0:
                task_depths[task] = 1
        
        # åŠ¨æ€è§„åˆ’è®¡ç®—æ·±åº¦
        changed = True
        while changed:
            changed = False
            for task in tasks:
                if task not in task_depths and all(parent in task_depths for parent in task.get_parents()):
                    parent_depths = [task_depths[parent] for parent in task.get_parents()]
                    task_depths[task] = max(parent_depths) + 1
                    changed = True
        
        # ç»Ÿè®¡æ¯å±‚ä»»åŠ¡æ•°
        depth_counts = {}
        for depth in task_depths.values():
            depth_counts[depth] = depth_counts.get(depth, 0) + 1
        
        return np.mean(list(depth_counts.values())) if depth_counts else 1
    
    def get_rag_suggestion(self, workflow_features, task_features, available_nodes):
        """è·å–RAGå»ºè®®"""
        # ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸ä¼¼æ¡ˆä¾‹
        similar_cases = self.knowledge_base.retrieve_similar_cases(
            workflow_features, task_features, top_k=5
        )
        
        if not similar_cases:
            return None, 0.0
        
        # ç»Ÿè®¡æ¯ä¸ªèŠ‚ç‚¹çš„æ¨èæ¬¡æ•°å’Œå¹³å‡æ€§èƒ½åˆ†æ•°
        node_scores = {}
        node_counts = {}
        
        for case in similar_cases:
            decision = case.decision
            score = case.performance_score
            
            if decision in node_scores:
                node_scores[decision] += score
                node_counts[decision] += 1
            else:
                node_scores[decision] = score
                node_counts[decision] = 1
        
        # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„å¹³å‡åˆ†æ•°
        avg_scores = {}
        for node in node_scores:
            avg_scores[node] = node_scores[node] / node_counts[node]
        
        # é€‰æ‹©æœ€ä½³èŠ‚ç‚¹
        best_node = max(avg_scores, key=avg_scores.get)
        confidence = avg_scores[best_node] / max(avg_scores.values()) if avg_scores else 0.0
        
        # å¦‚æœæœ€ä½³èŠ‚ç‚¹ä¸åœ¨å¯ç”¨èŠ‚ç‚¹ä¸­ï¼Œè¿”å›None
        if best_node not in available_nodes:
            return None, 0.0
        
        return best_node, confidence
    
    def get_teacher_suggestion(self, task, available_nodes, node_capacities, node_loads, teacher_type='WASS-Heuristic'):
        """è·å–æ•™å¸ˆè°ƒåº¦å™¨å»ºè®®"""
        if teacher_type == 'HEFT':
            # HEFTç­–ç•¥ï¼šé€‰æ‹©èƒ½æœ€æ—©å®Œæˆä»»åŠ¡çš„èŠ‚ç‚¹
            best_node = None
            best_finish_time = float('inf')
            
            for node in available_nodes:
                capacity = node_capacities.get(node, 1.0)
                load = node_loads.get(node, 0.0)
                exec_time = task.get_flops() / (capacity * 1e9)
                finish_time = load + exec_time
                
                if finish_time < best_finish_time:
                    best_finish_time = finish_time
                    best_node = node
            
            return best_node, 1.0  # HEFTæ€»æ˜¯æœ‰é«˜ç½®ä¿¡åº¦
        
        elif teacher_type == 'WASS-Heuristic':
            # WASS-Heuristicç­–ç•¥ï¼šè€ƒè™‘æ•°æ®å±€éƒ¨æ€§
            best_node = None
            best_score = float('inf')
            
            for node in available_nodes:
                # è®¡ç®—EFT
                capacity = node_capacities.get(node, 1.0)
                load = node_loads.get(node, 0.0)
                exec_time = task.get_flops() / (capacity * 1e9)
                eft = load + exec_time
                
                # ç®€åŒ–çš„DRTè®¡ç®—ï¼ˆæ¨¡æ‹Ÿæ•°æ®å±€éƒ¨æ€§ï¼‰
                drt = 0.0
                for parent in task.get_parents():
                    # å‡è®¾çˆ¶ä»»åŠ¡å¯èƒ½åœ¨ä»»ä½•èŠ‚ç‚¹ä¸Šæ‰§è¡Œ
                    if random.random() > 0.5:  # 50%æ¦‚ç‡éœ€è¦æ•°æ®ä¼ è¾“
                        file_size = task.get_flops() * 0.1  # å‡è®¾æ•°æ®å¤§å°
                        network_bandwidth = 1e9  # 1GB/s
                        drt += file_size / network_bandwidth
                
                # WASSè¯„åˆ†
                w = 0.5  # æ•°æ®å±€éƒ¨æ€§æƒé‡
                score = (1 - w) * eft + w * drt
                
                if score < best_score:
                    best_score = score
                    best_node = node
            
            return best_node, 1.0  # WASS-Heuristicæ€»æ˜¯æœ‰é«˜ç½®ä¿¡åº¦
        
        else:
            # é»˜è®¤éšæœºé€‰æ‹©
            return random.choice(available_nodes), 0.0
    
    def adaptive_fusion(self, drl_q_values, rag_suggestion, rag_confidence, teacher_suggestion, teacher_confidence):
        """è‡ªé€‚åº”èåˆDRLã€RAGå’Œæ•™å¸ˆå»ºè®®"""
        # æ ¹æ®å†å²æ€§èƒ½è°ƒæ•´æƒé‡
        if self.performance_history:
            recent_performance = np.mean(self.performance_history[-10:])
            if recent_performance > 0.8:  # å¦‚æœè¿‘æœŸæ€§èƒ½å¥½ï¼Œå¢åŠ DRLæƒé‡
                self.drl_weight = min(0.6, self.drl_weight + self.adaptation_rate)
                self.rag_weight = max(0.2, self.rag_weight - self.adaptation_rate * 0.5)
                self.teacher_weight = max(0.2, self.teacher_weight - self.adaptation_rate * 0.5)
            else:  # å¦‚æœè¿‘æœŸæ€§èƒ½å·®ï¼Œå¢åŠ æ•™å¸ˆå’ŒRAGæƒé‡
                self.drl_weight = max(0.1, self.drl_weight - self.adaptation_rate)
                self.rag_weight = min(0.5, self.rag_weight + self.adaptation_rate * 0.5)
                self.teacher_weight = min(0.4, self.teacher_weight + self.adaptation_rate * 0.5)
        
        # å½’ä¸€åŒ–æƒé‡
        total_weight = self.drl_weight + self.rag_weight + self.teacher_weight
        drl_w = self.drl_weight / total_weight
        rag_w = self.rag_weight / total_weight
        teacher_w = self.teacher_weight / total_weight
        
        # è®¡ç®—èåˆåˆ†æ•°
        fusion_scores = {}
        
        # DRLåˆ†æ•°
        for i, q_value in enumerate(drl_q_values):
            node = f"ComputeHost{i+1}"
            fusion_scores[node] = drl_w * float(q_value)
        
        # RAGåˆ†æ•°
        if rag_suggestion and rag_confidence > self.confidence_threshold:
            rag_score = rag_w * rag_confidence
            fusion_scores[rag_suggestion] = fusion_scores.get(rag_suggestion, 0) + rag_score
        
        # æ•™å¸ˆåˆ†æ•°
        if teacher_suggestion and teacher_confidence > self.confidence_threshold:
            teacher_score = teacher_w * teacher_confidence
            fusion_scores[teacher_suggestion] = fusion_scores.get(teacher_suggestion, 0) + teacher_score
        
        # é€‰æ‹©æœ€ä½³èŠ‚ç‚¹
        best_node = max(fusion_scores, key=fusion_scores.get)
        best_score = fusion_scores[best_node]
        
        return best_node, best_score
    
    def schedule(self, workflow, compute_service, drl_agent=None):
        """æ‰§è¡Œè°ƒåº¦"""
        try:
            import wrench
            
            # è·å–å¯ç”¨èŠ‚ç‚¹
            available_nodes = [host.get_name() for host in compute_service.get_hosts()]
            
            # èŠ‚ç‚¹å®¹é‡å’Œè´Ÿè½½
            node_capacities = {
                "ComputeHost1": 100.0,
                "ComputeHost2": 150.0,
                "ComputeHost3": 200.0,
                "ComputeHost4": 250.0
            }
            node_loads = {node: 0.0 for node in available_nodes}
            
            # æå–å·¥ä½œæµç‰¹å¾
            workflow_features = self.extract_workflow_features(workflow)
            
            # è·å–ä»»åŠ¡åˆ—è¡¨
            tasks = workflow.get_tasks()
            
            # æŒ‰ä¾èµ–å…³ç³»æ’åºä»»åŠ¡
            ready_tasks = [t for t in tasks if len(t.get_parents()) == 0]
            completed_tasks = set()
            
            # è°ƒåº¦å†³ç­–
            scheduling_decisions = []
            
            while ready_tasks:
                # é€‰æ‹©å½“å‰ä»»åŠ¡ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
                current_task = ready_tasks[0]
                
                # æå–ä»»åŠ¡ç‰¹å¾
                task_features = self.extract_task_features(current_task)
                
                # è·å–RAGå»ºè®®
                rag_suggestion, rag_confidence = self.get_rag_suggestion(
                    workflow_features, task_features, available_nodes
                )
                
                # è·å–æ•™å¸ˆå»ºè®®
                teacher_suggestion, teacher_confidence = self.get_teacher_suggestion(
                    current_task, available_nodes, node_capacities, node_loads
                )
                
                # è·å–DRLå»ºè®®
                drl_q_values = None
                if drl_agent:
                    # è¿™é‡Œéœ€è¦ä»DRLæ™ºèƒ½ä½“è·å–Qå€¼
                    # ç®€åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨éšæœºQå€¼
                    drl_q_values = np.random.rand(4)
                
                # èåˆå†³ç­–
                if drl_q_values is not None:
                    best_node, fusion_score = self.adaptive_fusion(
                        drl_q_values, rag_suggestion, rag_confidence,
                        teacher_suggestion, teacher_confidence
                    )
                else:
                    # æ²¡æœ‰DRLæ™ºèƒ½ä½“ï¼Œåªä½¿ç”¨RAGå’Œæ•™å¸ˆå»ºè®®
                    if rag_suggestion and teacher_suggestion:
                        # ç®€å•é€‰æ‹©ç½®ä¿¡åº¦æ›´é«˜çš„
                        if rag_confidence > teacher_confidence:
                            best_node = rag_suggestion
                        else:
                            best_node = teacher_suggestion
                    elif rag_suggestion:
                        best_node = rag_suggestion
                    elif teacher_suggestion:
                        best_node = teacher_suggestion
                    else:
                        best_node = random.choice(available_nodes)
                
                # æ‰§è¡Œè°ƒåº¦
                try:
                    # æ‰¾åˆ°å¯¹åº”çš„ä¸»æœºå¯¹è±¡
                    host = None
                    for h in compute_service.get_hosts():
                        if h.get_name() == best_node:
                            host = h
                            break
                    
                    if host:
                        # åˆ›å»ºæ ‡å‡†ä½œä¸š
                        standard_job = wrench.StandardJob([current_task])
                        
                        # æäº¤ä½œä¸š
                        compute_service.submit_standard_job(standard_job, {host})
                        
                        # æ›´æ–°èŠ‚ç‚¹è´Ÿè½½
                        capacity = node_capacities[best_node]
                        exec_time = current_task.get_flops() / (capacity * 1e9)
                        node_loads[best_node] += exec_time
                        
                        # è®°å½•å†³ç­–
                        decision = {
                            'task_id': current_task.get_id(),
                            'assigned_node': best_node,
                            'rag_suggestion': rag_suggestion,
                            'rag_confidence': rag_confidence,
                            'teacher_suggestion': teacher_suggestion,
                            'teacher_confidence': teacher_confidence,
                            'fusion_score': fusion_score if drl_q_values is not None else 0.0,
                            'weights': {
                                'drl': self.drl_weight,
                                'rag': self.rag_weight,
                                'teacher': self.teacher_weight
                            }
                        }
                        scheduling_decisions.append(decision)
                        
                        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                        completed_tasks.add(current_task)
                        ready_tasks.remove(current_task)
                        
                        # æ›´æ–°å°±ç»ªä»»åŠ¡åˆ—è¡¨
                        for child in current_task.get_children():
                            if all(parent in completed_tasks for parent in child.get_parents()):
                                if child not in ready_tasks:
                                    ready_tasks.append(child)
                    
                except Exception as e:
                    print(f"è°ƒåº¦ä»»åŠ¡å¤±è´¥: {e}")
                    # å¦‚æœè°ƒåº¦å¤±è´¥ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ªèŠ‚ç‚¹
                    best_node = random.choice(available_nodes)
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            makespan = max(node_loads.values()) if node_loads else 0.0
            
            # è®°å½•æ€§èƒ½
            performance_score = 1.0 / (makespan + 1e-6)
            self.performance_history.append(performance_score)
            self.decision_history.append(scheduling_decisions)
            
            return scheduling_decisions, makespan
            
        except Exception as e:
            print(f"è°ƒåº¦å¤±è´¥: {e}")
            return [], float('inf')
    
    def save_performance_stats(self, filepath):
        """ä¿å­˜æ€§èƒ½ç»Ÿè®¡"""
        stats = {
            'performance_history': self.performance_history,
            'decision_history': self.decision_history,
            'final_weights': {
                'drl': self.drl_weight,
                'rag': self.rag_weight,
                'teacher': self.teacher_weight
            }
        }
        
        with open(filepath, 'w') as f:
            json.dump(stats, f, indent=2)
        
        print(f"æ€§èƒ½ç»Ÿè®¡å·²ä¿å­˜: {filepath}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='WASS-RAGæ•™å¸ˆå¼•å¯¼è°ƒåº¦å™¨')
    parser.add_argument('--config', type=str, default='configs/experiment.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, default='results/teacher_guided_rag_stats.json', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = TeacherGuidedRAGScheduler(args.config)
    
    print("ğŸš€ æ•™å¸ˆå¼•å¯¼çš„RAGè°ƒåº¦å™¨å·²åˆ›å»º")
    print(f"   DRLæƒé‡: {scheduler.drl_weight:.3f}")
    print(f"   RAGæƒé‡: {scheduler.rag_weight:.3f}")
    print(f"   æ•™å¸ˆæƒé‡: {scheduler.teacher_weight:.3f}")
    print(f"   ç½®ä¿¡åº¦é˜ˆå€¼: {scheduler.confidence_threshold:.3f}")
    
    # ä¿å­˜åˆå§‹ç»Ÿè®¡
    scheduler.save_performance_stats(args.output)

if __name__ == '__main__':
    main()