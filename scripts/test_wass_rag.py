#!/usr/bin/env python3
"""
WASS-RAGç³»ç»Ÿæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯é‡æ„åçš„å¹³å°ã€å·¥ä½œæµç”Ÿæˆå™¨å’ŒAIè°ƒåº¦å™¨
"""

import os
import sys
import json
import time
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from src.ai_schedulers import create_scheduler, WASSRAGScheduler
from src.performance_predictor import PerformancePredictor
from src.drl_agent import DQNAgent
from scripts.workflow_generator import WorkflowGenerator
# ä»generate_ccr_workflowså¯¼å…¥ï¼ˆå¦‚æœéœ€è¦ï¼‰

def test_platform_config():
    """æµ‹è¯•å¹³å°é…ç½®"""
    print("=== æµ‹è¯•å¹³å°é…ç½® ===")
    
    platform_file = Path("configs/platform.xml")
    if not platform_file.exists():
        print("âŒ å¹³å°é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    with open(platform_file, 'r') as f:
        content = f.read()
        if 'latency="1ms"' in content:
            print("âœ… ç½‘ç»œå»¶è¿Ÿå·²è®¾ç½®ä¸º1ms")
        else:
            print("âŒ ç½‘ç»œå»¶è¿Ÿè®¾ç½®ä¸æ­£ç¡®")
            return False
    
    return True

def test_workflow_generator():
    """æµ‹è¯•å·¥ä½œæµç”Ÿæˆå™¨CCRæ”¯æŒ"""
    print("\n=== æµ‹è¯•å·¥ä½œæµç”Ÿæˆå™¨CCRæ”¯æŒ ===")
    
    # æµ‹è¯•ä¸åŒCCRå€¼çš„å·¥ä½œæµç”Ÿæˆ
    test_ccr_values = [0.1, 1.0, 5.0, 10.0]
    
    for ccr in test_ccr_values:
        try:
            generator = WorkflowGenerator(ccr=ccr)
            workflow_file = generator.generate_workflow_set("montage", [50])[0]
            
            print(f"âœ… CCR={ccr}: å·¥ä½œæµæ–‡ä»¶å·²ç”Ÿæˆ - {workflow_file}")
                
        except Exception as e:
            print(f"âŒ CCR={ccr}: ç”Ÿæˆé”™è¯¯ - {e}")
            return False
    
    return True

def test_gnn_predictor():
    """æµ‹è¯•GNNæ€§èƒ½é¢„æµ‹å™¨"""
    print("\n=== æµ‹è¯•GNNæ€§èƒ½é¢„æµ‹å™¨ ===")
    
    try:
        # åˆå§‹åŒ–é¢„æµ‹å™¨
        predictor = PerformancePredictor()
        
        # ç”Ÿæˆæµ‹è¯•å·¥ä½œæµ
        generator = WorkflowGenerator(ccr=1.0)
        workflow = generator.generate_workflow_set("montage", [20])[0]
        
        # æ„å»ºDAGå›¾
        import networkx as nx
        dag = nx.DiGraph()
        for task in workflow.tasks:
            dag.add_node(task.id, computation_size=task.computation_size)
        for edge in workflow.edges:
            dag.add_edge(edge.source, edge.target, data_size=edge.data_size)
        
        # æµ‹è¯•ç‰¹å¾æå–
        node_features = {'test_node': {'speed': 1.0, 'available_time': 0.0, 'queue_length': 0}}
        graph_data = predictor.extract_graph_features(dag, node_features, focus_task_id=workflow.tasks[0].id)
        
        if graph_data.x.shape[1] == 12:  # æ£€æŸ¥ç‰¹å¾ç»´åº¦
            print("âœ… GNNç‰¹å¾æå–æˆåŠŸ")
            
            # æµ‹è¯•é¢„æµ‹
            prediction = predictor.predict(graph_data)
            print(f"âœ… GNNé¢„æµ‹æˆåŠŸ: {prediction:.2f}")
            return True
        else:
            print(f"âŒ GNNç‰¹å¾ç»´åº¦é”™è¯¯: {graph_data.x.shape[1]} != 12")
            return False
            
    except Exception as e:
        print(f"âŒ GNNæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_rag_scheduler():
    """æµ‹è¯•RAGè°ƒåº¦å™¨"""
    print("\n=== æµ‹è¯•RAGè°ƒåº¦å™¨ ===")
    
    try:
        # åˆå§‹åŒ–ç»„ä»¶
        predictor = PerformancePredictor()
        drl_agent = DQNAgent(
            state_dim=50,  # æ ¹æ®å®é™…ç‰¹å¾ç»´åº¦è°ƒæ•´
            action_dim=4,  # 4ä¸ªè®¡ç®—èŠ‚ç‚¹
            learning_rate=0.001
        )
        
        node_names = ["host1", "host2", "host3", "host4"]
        scheduler = WASSRAGScheduler(drl_agent, node_names, predictor)
        
        print("âœ… RAGè°ƒåº¦å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•å¥–åŠ±æœºåˆ¶
        print("âœ… åŠ¨æ€å·®åˆ†å¥–åŠ±æœºåˆ¶å·²å¯ç”¨")
        return True
        
    except Exception as e:
        print(f"âŒ RAGè°ƒåº¦å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def run_benchmark_test():
    """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
    print("\n=== è¿è¡ŒåŸºå‡†æµ‹è¯• ===")
    
    try:
        # ç”Ÿæˆä¸åŒCCRçš„æµ‹è¯•å·¥ä½œæµ
        output_dir = Path("data/test_workflows")
        output_dir.mkdir(exist_ok=True)
        
        results = {}
        
        for ccr in [0.1, 1.0, 5.0, 10.0]:
            print(f"\næµ‹è¯•CCR={ccr}...")
            
            # ç”Ÿæˆå·¥ä½œæµ
            generator = WorkflowGenerator(ccr=ccr)
            workflow = generator.generate_workflow_set("montage", [30])[0]
            
            # ä¿å­˜å·¥ä½œæµ
            workflow_file = output_dir / f"test_workflow_ccr_{ccr}.json"
            with open(workflow_file, 'w') as f:
                json.dump({
                    "tasks": len(workflow.tasks),
                    "edges": len(workflow.edges),
                    "ccr": ccr,
                    "total_compute": sum(t.computation_size for t in workflow.tasks),
                    "total_comm": sum(e.data_size for e in workflow.edges)
                }, f, indent=2)
            
            results[f"CCR_{ccr}"] = {
                "tasks": len(workflow.tasks),
                "edges": len(workflow.edges),
                "total_compute": sum(t.computation_size for t in workflow.tasks),
                "total_comm": sum(e.data_size for e in workflow.edges)
            }
            
            print(f"  ä»»åŠ¡æ•°: {len(workflow.tasks)}, è¾¹æ•°: {len(workflow.edges)}")
            print(f"  æ€»è®¡ç®—é‡: {sum(t.computation_size for t in workflow.tasks):.2e}")
            print(f"  æ€»é€šä¿¡é‡: {sum(e.data_size for e in workflow.edges):.2e}")
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        with open("data/test_results.json", 'w') as f:
            json.dump(results, f, indent=2)
        
        print("\nâœ… åŸºå‡†æµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æµ‹è¯•WASS-RAGç³»ç»Ÿé‡æ„")
    parser.add_argument("--skip-platform", action="store_true", help="è·³è¿‡å¹³å°æµ‹è¯•")
    parser.add_argument("--skip-workflow", action="store_true", help="è·³è¿‡å·¥ä½œæµæµ‹è¯•")
    parser.add_argument("--skip-gnn", action="store_true", help="è·³è¿‡GNNæµ‹è¯•")
    parser.add_argument("--skip-rag", action="store_true", help="è·³è¿‡RAGæµ‹è¯•")
    parser.add_argument("--run-benchmark", action="store_true", help="è¿è¡ŒåŸºå‡†æµ‹è¯•")
    
    args = parser.parse_args()
    
    print("ğŸš€ WASS-RAGç³»ç»Ÿé‡æ„æµ‹è¯•")
    print("=" * 50)
    
    all_passed = True
    
    if not args.skip_platform:
        all_passed &= test_platform_config()
    
    if not args.skip_workflow:
        all_passed &= test_workflow_generator()
    
    if not args.skip_gnn:
        all_passed &= test_gnn_predictor()
    
    if not args.skip_rag:
        all_passed &= test_rag_scheduler()
    
    if args.run_benchmark:
        all_passed &= run_benchmark_test()
    
    print("\n" + "=" * 50)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼WASS-RAGç³»ç»Ÿé‡æ„å®Œæˆ")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
    
    return all_passed

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)