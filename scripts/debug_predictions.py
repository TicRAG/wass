#!/usr/bin/env python3
"""
è°ƒè¯•RAGè°ƒåº¦å™¨çš„å®é™…é¢„æµ‹å€¼
"""

import os
import sys
import torch
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)
sys.path.insert(0, os.path.join(parent_dir, 'src'))

try:
    from src.ai_schedulers import WASSRAGScheduler, PerformancePredictor
    print("âœ“ Successfully imported schedulers")
except ImportError as e:
    print(f"âœ— Import failed: {e}")
    sys.exit(1)

def test_performance_predictor():
    """ç›´æ¥æµ‹è¯•PerformancePredictorçš„è¾“å‡º"""
    
    print("=== Testing PerformancePredictor Directly ===")
    
    try:
        # åŠ è½½æ¨¡å‹
        checkpoint = torch.load("models/wass_models.pth", map_location="cpu")
        
        model = PerformancePredictor(input_dim=96, hidden_dim=128)
        model.load_state_dict(checkpoint["performance_predictor"])
        model.eval()
        
        # è·å–å½’ä¸€åŒ–å‚æ•°
        metadata = checkpoint["metadata"]["performance_predictor"]
        y_mean = metadata["y_mean"]
        y_std = metadata["y_std"]
        
        print(f"âœ“ Model loaded successfully")
        print(f"âœ“ Normalization params: mean={y_mean:.2f}, std={y_std:.2f}")
        
        # ç”Ÿæˆæµ‹è¯•ç‰¹å¾å‘é‡
        print(f"\nTesting with different feature vectors:")
        
        for i in range(5):
            # ç”Ÿæˆéšæœºç‰¹å¾å‘é‡ï¼ˆ96ç»´ï¼‰
            features = torch.randn(96)
            
            with torch.no_grad():
                # æ¨¡å‹é¢„æµ‹ï¼ˆå½’ä¸€åŒ–å€¼ï¼‰
                pred_normalized = model(features).item()
                
                # åå½’ä¸€åŒ–
                pred_denormalized = pred_normalized * y_std + y_mean
                
                print(f"Test {i+1}:")
                print(f"  Normalized prediction: {pred_normalized:.6f}")
                print(f"  Denormalized prediction: {pred_denormalized:.2f}")
                
                # æ£€æŸ¥æ˜¯å¦ä¼šè§¦å‘é™çº§é€»è¾‘
                trigger_condition = abs(pred_normalized) < 0.2 and abs(pred_normalized + 0.1) < 0.05
                if trigger_condition:
                    print(f"  âš ï¸  Would trigger degradation logic!")
                else:
                    print(f"  âœ“ Normal prediction")
        
        return True
        
    except Exception as e:
        print(f"âœ— Failed to test predictor: {e}")
        return False

def test_rag_scheduler_prediction():
    """æµ‹è¯•RAGè°ƒåº¦å™¨ä¸­çš„é¢„æµ‹è¿‡ç¨‹"""
    
    print(f"\n=== Testing RAG Scheduler Prediction Process ===")
    
    try:
        # åˆ›å»ºRAGè°ƒåº¦å™¨
        rag_scheduler = WASSRAGScheduler(
            model_path="models/wass_models.pth",
            knowledge_base_path="data/knowledge_base.pkl"
        )
        
        print(f"âœ“ RAG scheduler created")
        print(f"âœ“ Normalization params: mean={rag_scheduler._y_mean:.2f}, std={rag_scheduler._y_std:.2f}")
        
        # åˆ›å»ºå‡çš„è¾“å…¥
        state_embedding = torch.randn(32)
        action_embedding = torch.randn(32) 
        context = {"similar_cases": []}  # ç©ºä¸Šä¸‹æ–‡
        
        # è°ƒç”¨é¢„æµ‹å‡½æ•°
        print(f"\nTesting _predict_performance method:")
        predicted_makespan = rag_scheduler._predict_performance(
            state_embedding, action_embedding, context
        )
        
        print(f"Final predicted makespan: {predicted_makespan:.2f}")
        
        # å¤šæ¬¡æµ‹è¯•çœ‹æ˜¯å¦æœ‰å˜åŒ–
        print(f"\nTesting prediction diversity:")
        predictions = []
        for i in range(10):
            # ç¨å¾®ä¸åŒçš„è¾“å…¥
            state_emb = torch.randn(32)
            action_emb = torch.randn(32)
            
            pred = rag_scheduler._predict_performance(state_emb, action_emb, context)
            predictions.append(pred)
            print(f"  Prediction {i+1}: {pred:.2f}")
        
        # åˆ†æå¤šæ ·æ€§
        pred_std = np.std(predictions)
        pred_range = max(predictions) - min(predictions)
        unique_preds = len(set([round(p, 2) for p in predictions]))
        
        print(f"\nPrediction analysis:")
        print(f"  Standard deviation: {pred_std:.2f}")
        print(f"  Range: {pred_range:.2f}")
        print(f"  Unique predictions (rounded): {unique_preds}/10")
        
        if pred_std > 1.0:
            print(f"  âœ… Good prediction diversity")
            return True
        else:
            print(f"  âŒ Low prediction diversity")
            return False
            
    except Exception as e:
        print(f"âœ— Failed to test RAG scheduler: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("WASS-RAG Prediction Debugging")
    print("="*50)
    
    # æµ‹è¯•PerformancePredictor
    predictor_ok = test_performance_predictor()
    
    # æµ‹è¯•RAGè°ƒåº¦å™¨
    scheduler_ok = test_rag_scheduler_prediction()
    
    print(f"\n{'='*50}")
    if predictor_ok and scheduler_ok:
        print("ğŸ‰ SUCCESS: Both tests passed!")
        print("   The issue may be elsewhere in the scheduling pipeline")
    elif predictor_ok:
        print("âš ï¸  PARTIAL: Predictor works but scheduler has issues")
        print("   Check _predict_performance implementation")
    else:
        print("âŒ FAILURE: Core predictor issues detected")
        print("   Model loading or architecture problems")
    
    print(f"{'='*50}")
