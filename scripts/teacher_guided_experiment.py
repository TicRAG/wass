#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç»¼åˆå®éªŒè„šæœ¬ï¼šæµ‹è¯•æ•™å¸ˆå¼•å¯¼çš„DRLå’ŒRAGè°ƒåº¦å™¨
"""

import os
import sys
import json
import time
import random
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Any
import yaml
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

from src.wrench_schedulers import HEFTScheduler, WassHeuristicScheduler
from scripts.teacher_guided_drl_trainer import WRENCHBasedDRLTrainer
from scripts.teacher_guided_kb_generator import TeacherGuidedKnowledgeGenerator
from scripts.teacher_guided_rag_scheduler import TeacherGuidedRAGScheduler

class TeacherGuidedExperiment:
    """æ•™å¸ˆå¼•å¯¼çš„ç»¼åˆå®éªŒ"""
    
    def __init__(self, config_path: str):
        with open(config_path, 'r') as f:
            self.config = yaml.safe_load(f)
        
        self.exp_cfg = self.config.get('experiment', {})
        self.results_dir = Path(self.exp_cfg.get('results_dir', 'results/teacher_guided_experiments'))
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        # å®éªŒé…ç½®
        self.num_runs = self.exp_cfg.get('num_runs', 12)
        self.workflow_sizes = self.exp_cfg.get('workflow_sizes', [5, 10, 15, 20])
        
        # è°ƒåº¦å™¨
        self.schedulers = {
            'HEFT': HEFTScheduler(),
            'WASS-Heuristic': WassHeuristicScheduler(),
            'WASS-DRL': None,  # å°†åœ¨è®­ç»ƒååˆå§‹åŒ–
            'WASS-RAG': None   # å°†åœ¨åˆå§‹åŒ–åè®¾ç½®
        }
        
        # å®éªŒç»“æœ
        self.results = []
        self.detailed_results = []
    
    def generate_wrench_workflow(self, num_tasks: int, complexity: str = 'medium'):
        """ç”ŸæˆWRENCHå·¥ä½œæµ"""
        try:
            import wrench
            
            # åˆ›å»ºå·¥ä½œæµ
            workflow = wrench.Workflow()
            
            # åˆ›å»ºä»»åŠ¡
            tasks = []
            for i in range(num_tasks):
                # æ ¹æ®å¤æ‚åº¦è®¾ç½®ä»»åŠ¡å¤§å°
                if complexity == 'simple':
                    flops = random.uniform(1e9, 5e9)
                elif complexity == 'medium':
                    flops = random.uniform(1e9, 1e10)
                else:  # complex
                    flops = random.uniform(5e9, 2e10)
                
                task = workflow.add_task(f"task_{i}", flops)
                tasks.append(task)
            
            # ç”Ÿæˆä¾èµ–å…³ç³»
            if complexity == 'simple':
                # ç®€å•é“¾å¼ç»“æ„
                for i in range(1, num_tasks):
                    workflow.add_control_dependency(tasks[i-1], tasks[i])
            elif complexity == 'medium':
                # ä¸­ç­‰å¤æ‚åº¦ï¼Œæ¯ä¸ªä»»åŠ¡ä¾èµ–1-2ä¸ªå‰ç½®ä»»åŠ¡
                for i in range(1, num_tasks):
                    num_deps = min(random.randint(1, 2), i)
                    for j in range(max(0, i-num_deps), i):
                        workflow.add_control_dependency(tasks[j], tasks[i])
            else:  # complex
                # å¤æ‚ç»“æ„ï¼Œå¯èƒ½æœ‰å¤šä¸ªä¾èµ–å’Œåˆ†æ”¯
                for i in range(1, num_tasks):
                    num_deps = min(random.randint(1, 3), i)
                    deps = random.sample(range(i), num_deps)
                    for j in deps:
                        workflow.add_control_dependency(tasks[j], tasks[i])
            
            return workflow, tasks
            
        except Exception as e:
            print(f"ç”Ÿæˆå·¥ä½œæµå¤±è´¥: {e}")
            return None, None
    
    def run_scheduler_experiment(self, scheduler_name: str, workflow, tasks, run_id: int):
        """è¿è¡Œå•ä¸ªè°ƒåº¦å™¨å®éªŒ"""
        try:
            import wrench
            
            # åˆ›å»ºä»¿çœŸç¯å¢ƒ
            simulation = wrench.Simulation()
            
            # åˆ›å»ºå¹³å°
            platform = simulation.create_platform([
                wrench.Host("ComputeHost1", "100Gf", ["100Gf", "100GB"]),
                wrench.Host("ComputeHost2", "150Gf", ["150Gf", "150GB"]),
                wrench.Host("ComputeHost3", "200Gf", ["200Gf", "200GB"]),
                wrench.Host("ComputeHost4", "250Gf", ["250Gf", "250GB"])
            ])
            
            # åˆ›å»ºè®¡ç®—æœåŠ¡
            compute_service = simulation.create_bare_metal_compute_service(
                "ComputeService",
                platform.get_hosts(),
                {}
            )
            
            # æ·»åŠ å·¥ä½œæµåˆ°ä»¿çœŸ
            simulation.add_workflow(workflow)
            
            # è·å–è°ƒåº¦å™¨
            scheduler = self.schedulers[scheduler_name]
            
            # æ‰§è¡Œè°ƒåº¦
            start_time = time.time()
            
            if scheduler_name == 'WASS-RAG':
                # RAGè°ƒåº¦å™¨éœ€è¦ç‰¹æ®Šå¤„ç†
                scheduling_decisions, makespan = scheduler.schedule(workflow, compute_service)
            else:
                # å…¶ä»–è°ƒåº¦å™¨
                scheduler.schedule(workflow, compute_service)
                
                # å¯åŠ¨ä»¿çœŸ
                simulation.launch()
                
                # ç­‰å¾…å®Œæˆ
                simulation.wait_for_completion()
                
                # è®¡ç®—makespan
                makespan = max([task.get_end_time() for task in tasks])
            
            end_time = time.time()
            scheduling_time = end_time - start_time
            
            # æ”¶é›†è¯¦ç»†ç»“æœ
            detailed_result = {
                'run_id': run_id,
                'scheduler': scheduler_name,
                'workflow_size': len(tasks),
                'makespan': makespan,
                'scheduling_time': scheduling_time,
                'task_details': []
            }
            
            # æ”¶é›†ä»»åŠ¡è¯¦æƒ…
            for task in tasks:
                task_detail = {
                    'task_id': task.get_id(),
                    'flops': task.get_flops(),
                    'start_time': task.get_start_time(),
                    'end_time': task.get_end_time(),
                    'execution_time': task.get_execution_time(),
                    'assigned_host': task.get_execution_host().get_name() if task.get_execution_host() else None
                }
                detailed_result['task_details'].append(task_detail)
            
            return makespan, scheduling_time, detailed_result
            
        except Exception as e:
            print(f"è¿è¡Œè°ƒåº¦å™¨å®éªŒå¤±è´¥ {scheduler_name}: {e}")
            return float('inf'), float('inf'), None
    
    def train_drl_agent(self):
        """è®­ç»ƒDRLæ™ºèƒ½ä½“"""
        print("ğŸš€ å¼€å§‹è®­ç»ƒDRLæ™ºèƒ½ä½“...")
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = WRENCHBasedDRLTrainer(self.config)
        
        # è®­ç»ƒ
        episodes = self.config.get('drl', {}).get('episodes', 500)
        results = trainer.train(episodes)
        
        print(f"âœ… DRLè®­ç»ƒå®Œæˆ! æœ€ä½³Makespan: {results['best_makespan']:.2f}s")
        
        # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        model_path = Path(self.config.get('checkpoint', {}).get('dir', 'models/checkpoints/')) / 'wass_drl_teacher_guided.pth'
        
        if model_path.exists():
            checkpoint = torch.load(model_path, weights_only=False)
            # è¿™é‡Œéœ€è¦åˆå§‹åŒ–DRLæ™ºèƒ½ä½“å¹¶åŠ è½½æƒé‡
            # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥ä½¿ç”¨è®­ç»ƒå™¨ä¸­çš„æ™ºèƒ½ä½“
            self.schedulers['WASS-DRL'] = trainer.agent
            print(f"ğŸ“ DRLæ¨¡å‹å·²åŠ è½½: {model_path}")
        else:
            print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    def generate_knowledge_base(self):
        """ç”ŸæˆçŸ¥è¯†åº“"""
        print("ğŸš€ å¼€å§‹ç”ŸæˆçŸ¥è¯†åº“...")
        
        # åˆ›å»ºçŸ¥è¯†åº“ç”Ÿæˆå™¨
        generator = TeacherGuidedKnowledgeGenerator(self.config)
        
        # ç”ŸæˆçŸ¥è¯†åº“
        knowledge_base = generator.generate_knowledge_base()
        
        print(f"âœ… çŸ¥è¯†åº“ç”Ÿæˆå®Œæˆ! æ€»æ¡ˆä¾‹æ•°: {len(knowledge_base.cases)}")
    
    def initialize_rag_scheduler(self):
        """åˆå§‹åŒ–RAGè°ƒåº¦å™¨"""
        print("ğŸš€ åˆå§‹åŒ–RAGè°ƒåº¦å™¨...")
        
        # åˆ›å»ºRAGè°ƒåº¦å™¨
        rag_scheduler = TeacherGuidedRAGScheduler(self.config)
        
        # è®¾ç½®è°ƒåº¦å™¨
        self.schedulers['WASS-RAG'] = rag_scheduler
        
        print("âœ… RAGè°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def run_single_experiment(self, workflow_size: int, run_id: int):
        """è¿è¡Œå•æ¬¡å®éªŒ"""
        print(f"ğŸ“Š è¿è¡Œå®éªŒ: å·¥ä½œæµå¤§å° {workflow_size}, è¿è¡ŒID {run_id}")
        
        # ç”Ÿæˆå·¥ä½œæµ
        complexity = 'medium'  # ä½¿ç”¨ä¸­ç­‰å¤æ‚åº¦
        workflow, tasks = self.generate_wrench_workflow(workflow_size, complexity)
        
        if workflow is None:
            return None
        
        # è¿è¡Œæ‰€æœ‰è°ƒåº¦å™¨
        scheduler_results = {}
        
        for scheduler_name in self.schedulers:
            if self.schedulers[scheduler_name] is None:
                continue
            
            print(f"   è¿è¡Œè°ƒåº¦å™¨: {scheduler_name}")
            makespan, scheduling_time, detailed_result = self.run_scheduler_experiment(
                scheduler_name, workflow, tasks, run_id
            )
            
            scheduler_results[scheduler_name] = {
                'makespan': makespan,
                'scheduling_time': scheduling_time
            }
            
            # ä¿å­˜è¯¦ç»†ç»“æœ
            if detailed_result:
                self.detailed_results.append(detailed_result)
        
        return scheduler_results
    
    def run_all_experiments(self):
        """è¿è¡Œæ‰€æœ‰å®éªŒ"""
        print(f"ğŸš€ å¼€å§‹è¿è¡Œæ‰€æœ‰å®éªŒ: {self.num_runs} æ¬¡è¿è¡Œ")
        
        # è®­ç»ƒDRLæ™ºèƒ½ä½“
        self.train_drl_agent()
        
        # ç”ŸæˆçŸ¥è¯†åº“
        self.generate_knowledge_base()
        
        # åˆå§‹åŒ–RAGè°ƒåº¦å™¨
        self.initialize_rag_scheduler()
        
        # è¿è¡Œå®éªŒ
        for run_id in range(self.num_runs):
            print(f"\nğŸ¯ è¿è¡Œ {run_id + 1}/{self.num_runs}")
            
            # ä¸ºæ¯ä¸ªå·¥ä½œæµå¤§å°è¿è¡Œå®éªŒ
            for workflow_size in self.workflow_sizes:
                result = self.run_single_experiment(workflow_size, run_id)
                
                if result:
                    # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                    experiment_result = {
                        'run_id': run_id,
                        'workflow_size': workflow_size,
                        'results': result
                    }
                    self.results.append(experiment_result)
        
        # ä¿å­˜ç»“æœ
        self.save_results()
        
        # åˆ†æç»“æœ
        self.analyze_results()
    
    def save_results(self):
        """ä¿å­˜å®éªŒç»“æœ"""
        # ä¿å­˜è¯¦ç»†ç»“æœ
        detailed_path = self.results_dir / 'detailed_results.json'
        with open(detailed_path, 'w') as f:
            json.dump(self.detailed_results, f, indent=2)
        
        # ä¿å­˜æ±‡æ€»ç»“æœ
        summary_path = self.results_dir / 'summary_results.json'
        with open(summary_path, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜:")
        print(f"   è¯¦ç»†ç»“æœ: {detailed_path}")
        print(f"   æ±‡æ€»ç»“æœ: {summary_path}")
    
    def analyze_results(self):
        """åˆ†æå®éªŒç»“æœ"""
        print("\nğŸ“Š åˆ†æå®éªŒç»“æœ...")
        
        # æŒ‰è°ƒåº¦å™¨å’Œå·¥ä½œæµå¤§å°åˆ†ç»„
        scheduler_stats = {}
        
        for scheduler_name in self.schedulers:
            if self.schedulers[scheduler_name] is None:
                continue
            
            scheduler_stats[scheduler_name] = {
                'all_makespans': [],
                'all_scheduling_times': [],
                'by_workflow_size': {}
            }
            
            for size in self.workflow_sizes:
                scheduler_stats[scheduler_name]['by_workflow_size'][size] = {
                    'makespans': [],
                    'scheduling_times': []
                }
        
        # æ”¶é›†æ•°æ®
        for experiment in self.results:
            workflow_size = experiment['workflow_size']
            
            for scheduler_name, result in experiment['results'].items():
                makespan = result['makespan']
                scheduling_time = result['scheduling_time']
                
                # æ·»åŠ åˆ°æ€»ä½“ç»Ÿè®¡
                scheduler_stats[scheduler_name]['all_makespans'].append(makespan)
                scheduler_stats[scheduler_name]['all_scheduling_times'].append(scheduling_time)
                
                # æ·»åŠ åˆ°æŒ‰å¤§å°åˆ†ç»„çš„ç»Ÿè®¡
                scheduler_stats[scheduler_name]['by_workflow_size'][workflow_size]['makespans'].append(makespan)
                scheduler_stats[scheduler_name]['by_workflow_size'][workflow_size]['scheduling_times'].append(scheduling_time)
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        analysis_results = {}
        
        for scheduler_name, stats in scheduler_stats.items():
            # æ€»ä½“ç»Ÿè®¡
            all_makespans = stats['all_makespans']
            all_scheduling_times = stats['all_scheduling_times']
            
            analysis_results[scheduler_name] = {
                'avg_makespan': np.mean(all_makespans),
                'std_makespan': np.std(all_makespans),
                'min_makespan': np.min(all_makespans),
                'max_makespan': np.max(all_makespans),
                'avg_scheduling_time': np.mean(all_scheduling_times),
                'std_scheduling_time': np.std(all_scheduling_times),
                'by_workflow_size': {}
            }
            
            # æŒ‰å·¥ä½œæµå¤§å°ç»Ÿè®¡
            for size, size_stats in stats['by_workflow_size'].items():
                makespans = size_stats['makespans']
                scheduling_times = size_stats['scheduling_times']
                
                analysis_results[scheduler_name]['by_workflow_size'][size] = {
                    'avg_makespan': np.mean(makespans),
                    'std_makespan': np.std(makespans),
                    'min_makespan': np.min(makespans),
                    'max_makespan': np.max(makespans),
                    'avg_scheduling_time': np.mean(scheduling_times),
                    'std_scheduling_time': np.std(scheduling_times)
                }
        
        # ä¿å­˜åˆ†æç»“æœ
        analysis_path = self.results_dir / 'analysis_results.json'
        with open(analysis_path, 'w') as f:
            json.dump(analysis_results, f, indent=2)
        
        # æ‰“å°æ±‡æ€»ç»“æœ
        self.print_summary(analysis_results)
        
        print(f"ğŸ“Š åˆ†æç»“æœå·²ä¿å­˜: {analysis_path}")
    
    def print_summary(self, analysis_results):
        """æ‰“å°æ±‡æ€»ç»“æœ"""
        print("\n" + "="*80)
        print("ğŸ† æ•™å¸ˆå¼•å¯¼è°ƒåº¦å™¨æ€§èƒ½æ±‡æ€»")
        print("="*80)
        
        # æ‰¾å‡ºæœ€ä½³è°ƒåº¦å™¨
        best_scheduler = None
        best_makespan = float('inf')
        
        print("\n== å…¨å±€è°ƒåº¦å™¨æ€§èƒ½ ==")
        print(f"{'è°ƒåº¦å™¨':<15} {'å¹³å‡Makespan':<15} {'æ ‡å‡†å·®':<10} {'æœ€ä½³':<10} {'å®éªŒæ¬¡æ•°':<10}")
        print("-" * 70)
        
        for scheduler_name, stats in analysis_results.items():
            avg_makespan = stats['avg_makespan']
            std_makespan = stats['std_makespan']
            min_makespan = stats['min_makespan']
            count = len(stats['by_workflow_size'][self.workflow_sizes[0]]['makespans']) * len(self.workflow_sizes)
            
            print(f"{scheduler_name:<15} {avg_makespan:<15.2f} {std_makespan:<10.2f} {min_makespan:<10.2f} {count:<10}")
            
            if avg_makespan < best_makespan:
                best_makespan = avg_makespan
                best_scheduler = scheduler_name
        
        print(f"\nğŸ† æœ€ä½³è°ƒåº¦å™¨: {best_scheduler} (å¹³å‡Makespan: {best_makespan:.2f}s)")
        
        # æŒ‰å·¥ä½œæµå¤§å°æ‰“å°ç»“æœ
        print("\n== æŒ‰å·¥ä½œæµå¤§å°çš„å¹³å‡Makespan ==")
        for size in self.workflow_sizes:
            print(f"\nå·¥ä½œæµå¤§å° {size}")
            size_results = []
            
            for scheduler_name, stats in analysis_results.items():
                size_stats = stats['by_workflow_size'][size]
                avg_makespan = size_stats['avg_makespan']
                size_results.append((scheduler_name, avg_makespan))
            
            # æŒ‰æ€§èƒ½æ’åº
            size_results.sort(key=lambda x: x[1])
            
            for scheduler_name, avg_makespan in size_results:
                print(f"  {scheduler_name}: {avg_makespan:.2f}")
            
            # è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”
            if size_results:
                baseline = size_results[0][1]  # æœ€ä½³æ€§èƒ½
                for scheduler_name, avg_makespan in size_results[1:]:
                    improvement = ((avg_makespan - baseline) / baseline) * 100
                    print(f"  -> {scheduler_name} vs {size_results[0][0]}: {improvement:.2f}%")
        
        print("\n" + "="*80)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ•™å¸ˆå¼•å¯¼çš„WASS-DRLå’ŒRAGå®éªŒ')
    parser.add_argument('--config', type=str, default='configs/experiment.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--runs', type=int, default=12, help='å®éªŒè¿è¡Œæ¬¡æ•°')
    parser.add_argument('--workflow-sizes', type=str, default='5,10,15,20', help='å·¥ä½œæµå¤§å°ï¼Œé€—å·åˆ†éš”')
    
    args = parser.parse_args()
    
    # è§£æå·¥ä½œæµå¤§å°
    workflow_sizes = [int(s.strip()) for s in args.workflow_sizes.split(',')]
    
    # åˆ›å»ºå®éªŒ
    experiment = TeacherGuidedExperiment(args.config)
    
    # æ›´æ–°é…ç½®
    experiment.num_runs = args.runs
    experiment.workflow_sizes = workflow_sizes
    
    print(f"ğŸš€ å¼€å§‹æ•™å¸ˆå¼•å¯¼å®éªŒ:")
    print(f"   å®éªŒæ¬¡æ•°: {args.runs}")
    print(f"   å·¥ä½œæµå¤§å°: {workflow_sizes}")
    
    # è¿è¡Œå®éªŒ
    experiment.run_all_experiments()
    
    print("\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆ!")

if __name__ == '__main__':
    main()