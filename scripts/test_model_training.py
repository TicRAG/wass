#!/usr/bin/env python3
"""
æµ‹è¯•æ¨¡å‹è®­ç»ƒé€»è¾‘çš„ç®€åŒ–ç‰ˆæœ¬
ç”¨äºéªŒè¯PerformancePredictorè®­ç»ƒæ˜¯å¦èƒ½è§£å†³RAGè°ƒåº¦å™¨é—®é¢˜
"""

import os
import sys
import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Any
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)
sys.path.insert(0, os.path.join(parent_dir, 'src'))

# ç®€åŒ–çš„PerformancePredictorï¼ˆå¦‚æœAIæ¨¡å—ä¸å¯ç”¨ï¼‰
class SimplePerformancePredictor(nn.Module):
    """ç®€åŒ–çš„æ€§èƒ½é¢„æµ‹å™¨"""
    
    def __init__(self, input_dim=96, hidden_dim=128):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim // 2, 1)
        )
    
    def forward(self, x):
        return self.network(x)

def generate_test_data(num_samples: int = 1000) -> tuple:
    """ç”Ÿæˆæµ‹è¯•è®­ç»ƒæ•°æ®"""
    
    print(f"Generating {num_samples} test samples...")
    
    X = []  # ç‰¹å¾
    y = []  # ç›®æ ‡
    
    for i in range(num_samples):
        # ç”Ÿæˆ96ç»´ç‰¹å¾å‘é‡ (32 state + 32 action + 32 context)
        
        # State features (å·¥ä½œæµç‰¹å¾)
        task_count = np.random.randint(5, 51)
        state_features = np.array([
            task_count / 50.0,  # ä»»åŠ¡æ•°é‡å½’ä¸€åŒ–
            np.random.uniform(0.2, 0.8),  # ä¾èµ–æ¯”ä¾‹
            np.random.uniform(0.1, 0.5),  # æ•°æ®å¯†é›†åº¦
        ] + [np.random.randn() * 0.1 for _ in range(29)])  # å¡«å……åˆ°32ç»´
        
        # Action features (èŠ‚ç‚¹ç‰¹å¾)
        node_load = np.random.uniform(0.1, 0.9)
        action_features = np.array([
            node_load,  # èŠ‚ç‚¹è´Ÿè½½
            1.0 - node_load,  # ç©ºé—²åº¦
            np.random.uniform(0.5, 1.5),  # ç›¸å¯¹æ€§èƒ½
        ] + [np.random.randn() * 0.1 for _ in range(29)])  # å¡«å……åˆ°32ç»´
        
        # Context features (å†å²ä¿¡æ¯)
        context_features = np.array([
            np.random.uniform(0.3, 0.9),  # ç›¸ä¼¼åº¦
            np.random.uniform(0.5, 1.0),  # ç½®ä¿¡åº¦
        ] + [np.random.randn() * 0.1 for _ in range(30)])  # å¡«å……åˆ°32ç»´
        
        # åˆå¹¶ç‰¹å¾
        combined_features = np.concatenate([state_features, action_features, context_features])
        
        # ç”Ÿæˆç›®æ ‡å€¼ï¼ˆåŸºäºç‰¹å¾çš„åˆç†è®¡ç®—ï¼‰
        base_time = task_count * 2.0  # åŸºç¡€æ—¶é—´
        load_factor = 1.0 + node_load * 0.5  # è´Ÿè½½å½±å“
        performance_factor = action_features[2]  # æ€§èƒ½å½±å“
        noise = np.random.uniform(0.9, 1.1)  # éšæœºå™ªå£°
        
        makespan = base_time * load_factor / performance_factor * noise
        
        X.append(combined_features)
        y.append(makespan)
    
    return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)

def test_model_training():
    """æµ‹è¯•æ¨¡å‹è®­ç»ƒè¿‡ç¨‹"""
    
    print("=== Testing Model Training Logic ===")
    
    # 1. ç”Ÿæˆæµ‹è¯•æ•°æ®
    X, y = generate_test_data(1000)
    print(f"Generated data shape: X={X.shape}, y={y.shape}")
    print(f"Target range: {y.min():.2f} - {y.max():.2f}")
    print(f"Target mean: {y.mean():.2f} Â± {y.std():.2f}")
    
    # 2. æ•°æ®å½’ä¸€åŒ–
    y_mean, y_std = y.mean(), y.std()
    y_normalized = (y - y_mean) / y_std
    
    # 3. è½¬æ¢ä¸ºPyTorchå¼ é‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    X_tensor = torch.FloatTensor(X).to(device)
    y_tensor = torch.FloatTensor(y_normalized).to(device)
    
    # 4. åˆ›å»ºæ¨¡å‹
    model = SimplePerformancePredictor(input_dim=96, hidden_dim=128).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)
    criterion = nn.MSELoss()
    
    print(f"Model parameters: {sum(p.numel() for p in model.parameters())}")
    
    # 5. è®­ç»ƒå¾ªç¯
    epochs = 100
    batch_size = 32
    num_batches = len(X) // batch_size
    
    print(f"\nTraining for {epochs} epochs...")
    
    best_loss = float('inf')
    training_losses = []
    
    for epoch in range(epochs):
        model.train()
        epoch_loss = 0.0
        
        # ç®€å•çš„æ‰¹æ¬¡å¤„ç†
        for i in range(0, len(X_tensor), batch_size):
            batch_X = X_tensor[i:i+batch_size]
            batch_y = y_tensor[i:i+batch_size]
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            predictions = model(batch_X).squeeze()
            loss = criterion(predictions, batch_y)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
        
        avg_loss = epoch_loss / num_batches
        training_losses.append(avg_loss)
        
        if avg_loss < best_loss:
            best_loss = avg_loss
            best_model_state = model.state_dict().copy()
        
        if epoch % 20 == 0:
            print(f"Epoch {epoch:3d}: Loss = {avg_loss:.6f}")
    
    # 6. åŠ è½½æœ€ä½³æ¨¡å‹å¹¶è¯„ä¼°
    model.load_state_dict(best_model_state)
    model.eval()
    
    with torch.no_grad():
        all_predictions = model(X_tensor).squeeze().cpu().numpy()
        
        # åå½’ä¸€åŒ–
        all_predictions_denorm = all_predictions * y_std + y_mean
        
        # è®¡ç®—æŒ‡æ ‡
        mse = np.mean((all_predictions_denorm - y) ** 2)
        mae = np.mean(np.abs(all_predictions_denorm - y))
        r2 = 1 - np.sum((y - all_predictions_denorm) ** 2) / np.sum((y - y.mean()) ** 2)
        
        # æ£€æŸ¥é¢„æµ‹å¤šæ ·æ€§
        pred_std = np.std(all_predictions_denorm)
        pred_range = np.max(all_predictions_denorm) - np.min(all_predictions_denorm)
        unique_predictions = len(np.unique(np.round(all_predictions_denorm, 3)))
        
        print(f"\n=== Training Results ===")
        print(f"Final Loss: {best_loss:.6f}")
        print(f"MSE: {mse:.2f}")
        print(f"MAE: {mae:.2f}")
        print(f"RÂ²: {r2:.4f}")
        print(f"Prediction std: {pred_std:.2f}")
        print(f"Prediction range: {pred_range:.2f}")
        print(f"Unique predictions: {unique_predictions}/{len(y)}")
        
        # è¯Šæ–­ç»“æœ
        print(f"\n=== Diagnosis ===")
        if unique_predictions <= 1:
            print("âŒ CRITICAL: Model collapsed - all predictions identical!")
            print("   Root cause: Training data or model architecture issue")
        elif pred_std < 1.0:
            print("âš ï¸  WARNING: Low prediction diversity")
            print("   May cause limited differentiation in RAG scheduler")
        else:
            print("âœ… SUCCESS: Model shows good prediction diversity")
            print("   Should resolve RAG scheduler identical score issue")
        
        # è¾“å‡ºä¸€äº›æ ·æœ¬é¢„æµ‹
        print(f"\nSample predictions vs targets:")
        for i in range(min(10, len(y))):
            print(f"  Sample {i}: Pred={all_predictions_denorm[i]:.2f}, Target={y[i]:.2f}")
    
    return {
        "success": unique_predictions > 1 and pred_std >= 1.0,
        "mse": mse,
        "r2": r2,
        "prediction_diversity": pred_std,
        "unique_predictions": unique_predictions
    }

def save_test_results(results: Dict[str, Any]):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    
    results_file = "test_model_training_results.json"
    
    with open(results_file, 'w') as f:
        # å°†numpyç±»å‹è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹
        serializable_results = {}
        for key, value in results.items():
            if isinstance(value, (np.integer, np.floating)):
                serializable_results[key] = float(value)
            else:
                serializable_results[key] = value
        
        json.dump({
            "timestamp": "2025-09-08",
            "test_name": "performance_predictor_training",
            "results": serializable_results,
            "conclusion": "SUCCESS: Training produces diverse predictions" if results["success"] else "FAILURE: Training issues detected"
        }, f, indent=2)
    
    print(f"\nResults saved to: {results_file}")

if __name__ == "__main__":
    print("Testing WASS-RAG PerformancePredictor Training...")
    print("This test validates that proper training can solve the identical score issue.\n")
    
    results = test_model_training()
    save_test_results(results)
    
    print(f"\n{'='*60}")
    if results["success"]:
        print("ğŸ‰ CONCLUSION: Model training approach is VALIDATED!")
        print("   The enhanced training script should resolve RAG scheduler issues.")
        print("   Recommendation: Deploy the updated initialize_ai_models.py")
    else:
        print("âš ï¸  CONCLUSION: Training approach needs refinement.")
        print("   Additional work may be needed on data generation or model architecture.")
    
    print(f"{'='*60}")
