# scripts/seed_knowledge_base.py
import os
import sys
import json
import numpy as np
import torch
from pathlib import Path

# --- ä¿®æ­£å¯¼å…¥è·¯å¾„é—®é¢˜ ---
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)
# -------------------------

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from workflow_manager import WorkflowManager
from src.drl.gnn_encoder import GNNEncoder
from src.drl.knowledge_teacher import KnowledgeBase
from src.drl.utils import workflow_json_to_pyg_data
from src.wrench_schedulers import RecordingHEFTScheduler
from src.utils import WrenchExperimentRunner

# --- é…ç½®åŒº ---
GNN_IN_CHANNELS = 1
GNN_HIDDEN_CHANNELS = 64
GNN_OUT_CHANNELS = 32
KB_DIMENSION = GNN_OUT_CHANNELS
PLATFORM_FILE = "configs/test_platform.xml"
WORKFLOW_CONFIG_FILE = "configs/workflow_config.yaml"

# --- ä¸»é€»è¾‘ ---
def main():
    """ä¸»å‡½æ•°ï¼Œæ‰§è¡ŒçŸ¥è¯†åº“ç”Ÿæˆæµç¨‹"""
    print("ğŸš€ [Phase 1] Starting Knowledge Base Seeding Process...")
    
    # 1. åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶
    print("\n[Step 1/5] Initializing components...")
    workflow_manager = WorkflowManager(WORKFLOW_CONFIG_FILE)
    gnn_encoder = GNNEncoder(GNN_IN_CHANNELS, GNN_HIDDEN_CHANNELS, GNN_OUT_CHANNELS)
    knowledge_base = KnowledgeBase(dimension=KB_DIMENSION)
    
    # --- è¿™æ˜¯ä¿®æ­£çš„éƒ¨åˆ† ---
    # æ ¹æ®æ‚¨æä¾›çš„ utils.py çš„æ„é€ å‡½æ•° WrenchExperimentRunner.__init__(self, schedulers, config) è¿›è¡Œå®ä¾‹åŒ–
    # 1. æ„é€  config å‚æ•°
    config_params = {
        "platform_file": PLATFORM_FILE
        # WrenchExperimentRunneréœ€è¦çš„å…¶ä»–å‚æ•°å¯ä»¥æš‚æ—¶ä¸ºç©ºæˆ–é»˜è®¤ï¼Œå› ä¸ºæˆ‘ä»¬åªä½¿ç”¨å®ƒçš„å•ä¸ªæ¨¡æ‹ŸåŠŸèƒ½
    }
    # 2. schedulers å‚æ•°å¯ä»¥ä¸ºç©ºï¼Œå› ä¸ºæˆ‘ä»¬ä¸æ˜¯è¿è¡Œå¯¹æ¯”å®éªŒ
    schedulers_dict = {}

    # 3. ä½¿ç”¨æ­£ç¡®çš„å…³é”®å­—å‚æ•°è¿›è¡Œå®ä¾‹åŒ–
    wrench_runner = WrenchExperimentRunner(schedulers=schedulers_dict, config=config_params)
    print("âœ… Components initialized.")
    # --- ä¿®æ­£ç»“æŸ ---

    # 2. ç”Ÿæˆç”¨äºâ€œæ’­ç§â€çš„å·¥ä½œæµ
    print("\n[Step 2/5] Generating workflows for seeding...")
    seeding_workflows = workflow_manager.generate_training_workflows()
    if not seeding_workflows:
        print("âŒ No workflows generated. Please check your config.")
        return
    print(f"âœ… Generated {len(seeding_workflows)} workflows.")

    # 3. å¾ªç¯å¤„ç†æ¯ä¸ªå·¥ä½œæµ
    print("\n[Step 3/5] Simulating workflows with HEFT to gather experience...")
    all_embeddings = []
    all_metadata = []

    for i, wf_file in enumerate(seeding_workflows):
        wf_path = Path(wf_file)
        print(f"\n--- Processing workflow {i+1}/{len(seeding_workflows)}: {wf_path.name} ---")

        # a. è°ƒç”¨ WrenchExperimentRunner çš„æ–°æ–¹æ³•
        #    åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æ˜ç¡®å‘Šè¯‰å®ƒæœ¬æ¬¡æ¨¡æ‹Ÿä½¿ç”¨ RecordingHEFTScheduler
        print(f"  â–¶ï¸ Running WRENCH simulation via WrenchExperimentRunner using HEFT...")
        makespan, decisions = wrench_runner.run_single_seeding_simulation(
            scheduler_class=RecordingHEFTScheduler,
            workflow_file=str(wf_path)
        )

        # b. æ£€æŸ¥æ¨¡æ‹Ÿæ˜¯å¦æˆåŠŸ
        if makespan < 0 or not decisions:
            print(f"âŒ Simulation failed for {wf_path.name}. Skipping.")
            continue
        
        print(f"  â¹ï¸ Simulation finished. Makespan: {makespan:.2f} seconds.")
        print(f"  ğŸ“ Recorded {len(decisions)} scheduling decisions.")

        # c. å°†å·¥ä½œæµå›¾ç¼–ç ä¸ºå‘é‡
        try:
            pyg_data = workflow_json_to_pyg_data(str(wf_path))
            graph_embedding = gnn_encoder(pyg_data)
        except Exception as e:
            print(f"âŒ Error encoding workflow {wf_path.name} to graph: {e}")
            continue

        # d. å‡†å¤‡å­˜å‚¨æ•°æ®
        all_embeddings.append(graph_embedding.detach().numpy().flatten())
        all_metadata.append({
            "workflow_file": wf_path.name,
            "makespan": makespan,
            "decisions": json.dumps(decisions) 
        })
            
    print("\n--- All workflows processed ---")

    # 4. å°†æ”¶é›†åˆ°çš„æ‰€æœ‰æ•°æ®æ·»åŠ åˆ°çŸ¥è¯†åº“
    print("\n[Step 4/5] Adding all collected experience to the Knowledge Base...")
    if not all_embeddings:
        print("âŒ No experience was collected. Cannot build knowledge base.")
        return
        
    knowledge_base.add(np.array(all_embeddings), all_metadata)
    print(f"âœ… Added {len(all_embeddings)} entries to the knowledge base.")

    # 5. ä¿å­˜çŸ¥è¯†åº“åˆ°ç£ç›˜
    print("\n[Step 5/5] Saving the Knowledge Base to disk...")
    knowledge_base.save()
    print(f"âœ… Knowledge Base saved successfully to '{knowledge_base.storage_path}'")
    print("\nğŸ‰ [Phase 1] Knowledge Base Seeding Process Completed! ğŸ‰")


if __name__ == "__main__":
    main()