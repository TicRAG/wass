#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
WASS-RAG å·¥ä½œæµç®¡ç†å™¨
ç»Ÿä¸€ç®¡ç†è®­ç»ƒå’Œå®éªŒä¸­ä½¿ç”¨çš„å·¥ä½œæµï¼Œç¡®ä¿ç”Ÿæˆæ–¹å¼ä¸€è‡´
"""

import os
import sys
import json
import yaml
import random
from pathlib import Path
from typing import List, Dict, Any, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from scripts.workflow_generator import WorkflowGenerator

class WorkflowManager:
    """å·¥ä½œæµç®¡ç†å™¨ï¼Œç»Ÿä¸€ç®¡ç†å·¥ä½œæµçš„ç”Ÿæˆã€é…ç½®å’Œä½¿ç”¨"""
    
    def __init__(self, config_path: str = "configs/workflow_config.yaml"):
        """åˆå§‹åŒ–å·¥ä½œæµç®¡ç†å™¨"""
        self.config_path = config_path
        self._load_config()
        
        # åˆå§‹åŒ–å·¥ä½œæµç”Ÿæˆå™¨
        self.generator = WorkflowGenerator(
            output_dir=self.config.get('workflow_dir', 'workflows'),
            ccr=self.config.get('ccr', 1.0)
        )
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.workflow_dir = Path(self.config.get('workflow_dir', 'workflows'))
        self.workflow_dir.mkdir(parents=True, exist_ok=True)
    
    def _load_config(self):
        """åŠ è½½å·¥ä½œæµé…ç½®"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
        except FileNotFoundError:
            # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
            self.config = {
                'workflow_dir': 'workflows',
                'patterns': ['montage', 'highly_parallel'],
                'small_sizes': [5, 10, 15, 20],
                'medium_sizes': [50, 100],
                'large_sizes': [200, 500],
                'ccr': 1.0,
                'random_seed': 42
            }
            # ä¿å­˜é»˜è®¤é…ç½®
            os.makedirs(Path(self.config_path).parent, exist_ok=True)
            with open(self.config_path, 'w', encoding='utf-8') as f:
                yaml.dump(self.config, f, default_flow_style=False, allow_unicode=True)
            print(f"ğŸ“ åˆ›å»ºé»˜è®¤å·¥ä½œæµé…ç½®æ–‡ä»¶: {self.config_path}")
    
    def generate_experiment_workflows(self) -> List[str]:
        """ç”Ÿæˆå®éªŒç”¨å·¥ä½œæµ"""
        # è·å–é…ç½®çš„å·¥ä½œæµå¤§å°
        workflow_sizes = self.config.get('small_sizes', [5, 10, 15, 20])
        patterns = self.config.get('patterns', ['montage'])
        random_seed = self.config.get('random_seed', 42)
        
        generated_files = []
        
        for pattern in patterns:
            for size in workflow_sizes:
                # ç”Ÿæˆç”¨äºå®éªŒçš„å·¥ä½œæµï¼Œä½¿ç”¨æ ‡å‡†æ ¼å¼ï¼ˆæ”¯æŒWrenchExperimentRunnerçš„æœç´¢ï¼‰
                # æ ¼å¼1: {pattern}_{size}.json - ç”¨äºWrenchExperimentRunneræœç´¢
                # æ ¼å¼2: {pattern}_{size}_tasks.json - ä¿æŒä¸åŸç”Ÿæˆå™¨å…¼å®¹
                
                # å…ˆç”Ÿæˆæ ‡å‡†æ ¼å¼
                filename_std = f"{pattern}_{size}.json"
                file_path = self.generator.generate_single_workflow(
                    pattern=pattern,
                    task_count=size,
                    random_seed=random_seed,
                    filename=filename_std
                )
                generated_files.append(file_path)
                
                # å†ç”Ÿæˆå…¼å®¹æ ¼å¼ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                filename_compat = f"{pattern}_{size}_tasks.json"
                if not (self.workflow_dir / filename_compat).exists():
                    # åˆ›å»ºç¬¦å·é“¾æ¥ä»¥é¿å…é‡å¤æ–‡ä»¶
                    try:
                        os.symlink(filename_std, self.workflow_dir / filename_compat)
                        print(f"ğŸ”— åˆ›å»ºå…¼å®¹é“¾æ¥: {filename_compat} -> {filename_std}")
                    except OSError:
                        # å¦‚æœä¸æ”¯æŒç¬¦å·é“¾æ¥ï¼Œå°±å¤åˆ¶æ–‡ä»¶
                        with open(self.workflow_dir / filename_std, 'r') as f:
                            content = json.load(f)
                        with open(self.workflow_dir / filename_compat, 'w') as f:
                            json.dump(content, f, indent=2)
                        print(f"ğŸ“‹ åˆ›å»ºå…¼å®¹æ–‡ä»¶: {filename_compat}")
        
        return generated_files
    
    def generate_training_workflows(self) -> List[str]:
        """ç”Ÿæˆè®­ç»ƒç”¨å·¥ä½œæµ"""
        # è®­ç»ƒå·¥ä½œæµå¯ä»¥ä½¿ç”¨ä¸­ç­‰è§„æ¨¡ï¼Œå¢åŠ è®­ç»ƒæ•°æ®å¤šæ ·æ€§
        workflow_sizes = self.config.get('medium_sizes', [50, 100])
        patterns = self.config.get('patterns', ['montage'])
        random_seed = self.config.get('random_seed', 42)
        
        # ä¸ºäº†å¢åŠ è®­ç»ƒå¤šæ ·æ€§ï¼Œä½¿ç”¨ä¸åŒçš„éšæœºç§å­
        generated_files = []
        
        for pattern in patterns:
            for size in workflow_sizes:
                for seed_offset in range(3):  # ä¸ºæ¯ç§è§„æ¨¡ç”Ÿæˆ3ä¸ªä¸åŒçš„éšæœºå˜ä½“
                    filename = f"{pattern}_{size}_seed{random_seed + seed_offset}_training.json"
                    file_path = self.generator.generate_single_workflow(
                        pattern=pattern,
                        task_count=size,
                        random_seed=random_seed + seed_offset,
                        filename=filename
                    )
                    generated_files.append(file_path)
        
        return generated_files
    
    def generate_all_workflows(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆæ‰€æœ‰éœ€è¦çš„å·¥ä½œæµ"""
        print("ğŸš€ å¼€å§‹ç”Ÿæˆæ‰€æœ‰å·¥ä½œæµ...")
        
        # ç”Ÿæˆå®éªŒç”¨å·¥ä½œæµ
        exp_workflows = self.generate_experiment_workflows()
        print(f"âœ… å®éªŒå·¥ä½œæµç”Ÿæˆå®Œæˆ: {len(exp_workflows)} ä¸ªæ–‡ä»¶")
        
        # ç”Ÿæˆè®­ç»ƒç”¨å·¥ä½œæµ
        train_workflows = self.generate_training_workflows()
        print(f"âœ… è®­ç»ƒå·¥ä½œæµç”Ÿæˆå®Œæˆ: {len(train_workflows)} ä¸ªæ–‡ä»¶")
        
        # åˆ›å»ºå·¥ä½œæµæ¸…å•
        self._create_workflow_inventory(exp_workflows, train_workflows)
        
        return {
            'experiment': exp_workflows,
            'training': train_workflows
        }
    
    def _create_workflow_inventory(self, exp_workflows: List[str], train_workflows: List[str]):
        """åˆ›å»ºå·¥ä½œæµæ¸…å•"""
        inventory = {
            'experiment_workflows': [Path(f).name for f in exp_workflows],
            'training_workflows': [Path(f).name for f in train_workflows],
            'config': self.config
        }
        
        inventory_path = self.workflow_dir / "workflow_inventory.json"
        with open(inventory_path, 'w', encoding='utf-8') as f:
            json.dump(inventory, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“‹ å·¥ä½œæµæ¸…å•å·²ä¿å­˜: {inventory_path}")
    
    def get_workflow_paths(self, size: int) -> List[str]:
        """è·å–ç‰¹å®šå¤§å°çš„å·¥ä½œæµè·¯å¾„"""
        pattern = f"*_{size}.json"
        paths = list(self.workflow_dir.glob(pattern))
        return [str(p) for p in paths]
    
    def validate_workflows(self) -> bool:
        """éªŒè¯æ‰€æœ‰å·¥ä½œæµæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
        valid = True
        
        for file_path in self.workflow_dir.glob("*.json"):
            try:
                with open(file_path, 'r') as f:
                    data = json.load(f)
                # æ£€æŸ¥å¿…è¦å­—æ®µ
                assert 'metadata' in data and 'workflow' in data
                assert 'tasks' in data['workflow'] and 'files' in data['workflow']
            except Exception as e:
                print(f"âŒ å·¥ä½œæµæ–‡ä»¶æ— æ•ˆ: {file_path} - {e}")
                valid = False
        
        return valid

def update_experiment_config():
    """æ›´æ–°å®éªŒé…ç½®æ–‡ä»¶ï¼Œç¡®ä¿ä½¿ç”¨ç»Ÿä¸€çš„å·¥ä½œæµè®¾ç½®"""
    experiment_config_path = "configs/real_heuristic_experiment.yaml"
    
    try:
        with open(experiment_config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # ç¡®ä¿å·¥ä½œæµé…ç½®ä¸å·¥ä½œæµç®¡ç†å™¨ä¸€è‡´
        workflow_manager = WorkflowManager()
        
        # æ›´æ–°å·¥ä½œæµç›®å½•é…ç½®
        config['workflow_dir'] = workflow_manager.config.get('workflow_dir', 'workflows')
        
        # ä»…åœ¨é…ç½®ä¸­æ²¡æœ‰æŒ‡å®šå·¥ä½œæµå¤§å°æ—¶æ‰è®¾ç½®é»˜è®¤å€¼
        if 'workflow_sizes' not in config:
            config['workflow_sizes'] = workflow_manager.config.get('small_sizes', [5, 10, 15, 20])
        
        # ä¿å­˜æ›´æ–°åçš„é…ç½®
        with open(experiment_config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… å®éªŒé…ç½®å·²æ›´æ–°: {experiment_config_path}")
        return True
    except Exception as e:
        print(f"âŒ æ›´æ–°å®éªŒé…ç½®å¤±è´¥: {e}")
        return False


def update_drl_config():
    """æ›´æ–°DRLè®­ç»ƒé…ç½®ï¼Œç¡®ä¿ä¸å®éªŒä½¿ç”¨ç»Ÿä¸€çš„å·¥ä½œæµè®¾ç½®"""
    drl_config_path = "configs/drl.yaml"
    
    try:
        with open(drl_config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # ç¡®ä¿å·¥ä½œæµé…ç½®ä¸å·¥ä½œæµç®¡ç†å™¨ä¸€è‡´
        workflow_manager = WorkflowManager()
        
        # æ›´æ–°å¹³å°æ–‡ä»¶è·¯å¾„ï¼Œä¿æŒä¸å®éªŒä¸€è‡´
        experiment_config_path = "configs/real_heuristic_experiment.yaml"
        if os.path.exists(experiment_config_path):
            with open(experiment_config_path, 'r', encoding='utf-8') as f_exp:
                exp_config = yaml.safe_load(f_exp)
                if 'platform_file' in exp_config:
                    config['platform_file'] = exp_config['platform_file']
        
        # è·å–å·¥ä½œæµç®¡ç†å™¨ä¸­çš„å°è§„æ¨¡å·¥ä½œæµå¤§å°
        small_sizes = workflow_manager.config.get('small_sizes', [5, 10, 15, 20])
        if small_sizes:
            # è®¾ç½®ä»»åŠ¡èŒƒå›´ä¸ºæœ€å°å’Œæœ€å¤§çš„å·¥ä½œæµå¤§å°
            config['task_range'] = [min(small_sizes), max(small_sizes)]
        
        # ä¿å­˜æ›´æ–°åçš„é…ç½®
        with open(drl_config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… DRLè®­ç»ƒé…ç½®å·²æ›´æ–°: {drl_config_path}")
        return True
    except Exception as e:
        print(f"âŒ æ›´æ–°DRLè®­ç»ƒé…ç½®å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    import sys
    import argparse
    parser = argparse.ArgumentParser(description='WASS-RAG å·¥ä½œæµç®¡ç†å™¨')
    parser.add_argument('--action', choices=['generate', 'validate', 'update_config', 'update_all_configs'], 
                        default='generate',
                        help='æ‰§è¡Œçš„æ“ä½œ: ç”Ÿæˆå·¥ä½œæµã€éªŒè¯å·¥ä½œæµã€æ›´æ–°å®éªŒé…ç½®æˆ–æ›´æ–°æ‰€æœ‰é…ç½®')
    parser.add_argument('--config', default='configs/workflow_config.yaml',
                        help='å·¥ä½œæµé…ç½®æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    if args.action == 'generate':
        workflow_manager = WorkflowManager(args.config)
        workflow_manager.generate_experiment_workflows()
        workflow_manager.generate_training_workflows()
    elif args.action == 'validate':
        workflow_manager = WorkflowManager(args.config)
        workflow_manager.validate_workflows()
    elif args.action == 'update_config':
        # ä»…æ›´æ–°å®éªŒé…ç½®
        if update_experiment_config():
            print("âœ… å®éªŒé…ç½®æ›´æ–°å®Œæˆ!")
        else:
            sys.exit(1)
    elif args.action == 'update_all_configs':
        # æ›´æ–°æ‰€æœ‰é…ç½®æ–‡ä»¶ä»¥ç¡®ä¿ä¸€è‡´æ€§
        if update_experiment_config() and update_drl_config():
            print("âœ… æ‰€æœ‰é…ç½®æ›´æ–°å®Œæˆ!")
        else:
            sys.exit(1)
    else:
        print(f"æœªçŸ¥çš„æ“ä½œ: {args.action}")

if __name__ == "__main__":
    main()