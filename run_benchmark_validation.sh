#!/bin/bash

# WASS-RAG åŸºå‡†éªŒè¯å®éªŒè„šæœ¬
# åœ¨"å…¬å¹³èµ›é“"æ¨¡å¼ä¸‹éªŒè¯HEFT vs FIFOçš„æ€§èƒ½å¯¹æ¯”

set -e

echo "ğŸš€ å¯åŠ¨WASS-RAGåŸºå‡†éªŒè¯å®éªŒ..."
echo "================================================"

# è®¾ç½®å®éªŒå‚æ•°
EXPERIMENT_NAME="benchmark_validation"
WORKFLOW_CCR=10.0  # é«˜CCRå€¼ï¼Œç¡®ä¿HEFTä¼˜åŠ¿
REPETITIONS=5      # é‡å¤å®éªŒæ¬¡æ•°
TASK_COUNTS="50,100,200"  # æµ‹è¯•çš„å·¥ä½œæµè§„æ¨¡
SCHEDULERS="HEFT,FIFO"    # ä»…æµ‹è¯•HEFTå’ŒFIFO

# åˆ›å»ºå®éªŒç›®å½•
EXPERIMENT_DIR="experiments/${EXPERIMENT_NAME}"
mkdir -p "${EXPERIMENT_DIR}"
mkdir -p "${EXPERIMENT_DIR}/workflows"
mkdir -p "${EXPERIMENT_DIR}/platforms"
mkdir -p "${EXPERIMENT_DIR}/results"

echo "ğŸ“ å®éªŒç›®å½•: ${EXPERIMENT_DIR}"
echo "ğŸ¯ å·¥ä½œæµCCR: ${WORKFLOW_CCR}"
echo "ğŸ” é‡å¤æ¬¡æ•°: ${REPETITIONS}"
echo "ğŸ“Š æµ‹è¯•è§„æ¨¡: ${TASK_COUNTS}"
echo "âš–ï¸  è°ƒåº¦å™¨: ${SCHEDULERS}"

# æ­¥éª¤1: é¢„ç”Ÿæˆæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹ï¼ˆå…¬å¹³èµ›é“æ¨¡å¼ï¼‰
echo ""
echo "ğŸ“‹ æ­¥éª¤1: é¢„ç”Ÿæˆå›ºå®šæµ‹è¯•ç”¨ä¾‹..."
python3 << 'EOF'
import sys
import os
sys.path.append('scripts')

from workflow_generator import WorkflowGenerator
from platform_generator import PlatformGenerator
import json

# å®éªŒå‚æ•°
experiment_name = "benchmark_validation"
workflow_ccr = 10.0
repetitions = 5
task_counts = [50, 100, 200]
scales = ['small', 'medium', 'large']

# åˆ›å»ºæµ‹è¯•ç”¨ä¾‹
experiment_dir = f"experiments/{experiment_name}"
workflow_dir = f"{experiment_dir}/workflows"
platform_dir = f"{experiment_dir}/platforms"

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(workflow_dir, exist_ok=True)
os.makedirs(platform_dir, exist_ok=True)

# ç”Ÿæˆæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
test_cases = []

print("ğŸ”§ ç”Ÿæˆå·¥ä½œæµå’Œå¹³å°é…ç½®...")

workflow_gen = WorkflowGenerator()
platform_gen = PlatformGenerator(seed=42)  # å›ºå®šç§å­ç¡®ä¿å¯é‡ç°

for task_count in task_counts:
    for rep in range(repetitions):
        for scale in scales:
            # ç”Ÿæˆå·¥ä½œæµ
            workflow_file = f"{workflow_dir}/workflow_montage_{task_count}_rep{rep}.json"
            workflow_path = workflow_gen.generate_single_workflow(
                pattern='montage',
                task_count=task_count,
                random_seed=42 + rep,  # æ¯ä¸ªé‡å¤ä½¿ç”¨ä¸åŒä½†å›ºå®šçš„ç§å­
                filename=f"workflow_montage_{task_count}_rep{rep}.json"
            )
            
            # ç”Ÿæˆå¹³å°
            platform_file = platform_gen.generate_single_platform(
                scale=scale,
                repetition_index=rep,
                seed=42
            )
            
            test_case = {
                'workflow_file': workflow_path,
                'platform_file': platform_file,
                'task_count': task_count,
                'scale': scale,
                'repetition': rep,
                'ccr': workflow_ccr
            }
            test_cases.append(test_case)

# ä¿å­˜æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
with open(f"{experiment_dir}/test_cases.json", 'w') as f:
    json.dump(test_cases, f, indent=2)

print(f"âœ… ç”Ÿæˆäº† {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
print("ğŸ“Š æµ‹è¯•ç”¨ä¾‹å·²ä¿å­˜åˆ° test_cases.json")
EOF

# æ­¥éª¤2: è¿è¡Œå…¬å¹³å®éªŒ
echo ""
echo "âš–ï¸  æ­¥éª¤2: åœ¨å…¬å¹³èµ›é“ä¸Šè¿è¡Œå®éªŒ..."
python3 scripts/fair_experiment_controller.py \
    --mode "custom" \
    --patterns montage \
    --sizes 50 100 200 \
    --scales small medium large \
    --schedulers FIFO HEFT \
    --repeats 5

# æ­¥éª¤3: ç”ŸæˆéªŒè¯æŠ¥å‘Š
echo ""
echo "ğŸ“Š æ­¥éª¤3: ç”ŸæˆéªŒè¯æŠ¥å‘Š..."
python3 << 'EOF'
import pandas as pd
import json
import os
import numpy as np
import glob

# æŸ¥æ‰¾æœ€æ–°çš„å®éªŒç»“æœæ–‡ä»¶
results_dir = "results/fair_experiments"

# æŸ¥æ‰¾æœ€æ–°çš„CSVç»“æœæ–‡ä»¶
csv_files = glob.glob(f"{results_dir}/fair_experiment_results_*.csv")
if not csv_files:
    print("âŒ æœªæ‰¾åˆ°å®éªŒç»“æœæ–‡ä»¶")
    exit(1)

# åŠ è½½å®éªŒç»“æœ
latest_csv = max(csv_files, key=os.path.getctime)
print(f"ğŸ“Š ä½¿ç”¨ç»“æœæ–‡ä»¶: {latest_csv}")

# åŠ è½½å®éªŒç»“æœ
df = pd.read_csv(latest_csv)

# è®¡ç®—HEFT vs FIFOçš„å¯¹æ¯”
summary = []
for workflow_size in df['workflow_size'].unique():
    for scale in df['platform_scale'].unique():
        subset = df[(df['workflow_size'] == workflow_size) & (df['platform_scale'] == scale)]
        
        heft_makespan = subset[subset['scheduler'] == 'HEFT']['makespan'].mean()
        fifo_makespan = subset[subset['scheduler'] == 'FIFO']['makespan'].mean()
        
        improvement = ((fifo_makespan - heft_makespan) / fifo_makespan) * 100
        
        summary.append({
            'workflow_size': workflow_size,
            'platform_scale': scale,
            'heft_makespan': round(heft_makespan, 2),
            'fifo_makespan': round(fifo_makespan, 2),
            'improvement_percent': round(improvement, 2),
            'heft_wins': len(subset[subset['scheduler'] == 'HEFT'])
        })

summary_df = pd.DataFrame(summary)

# ä¿å­˜éªŒè¯æŠ¥å‘Šåˆ°å®éªŒç›®å½•
experiment_dir = "experiments/benchmark_validation"
os.makedirs(f"{experiment_dir}/results", exist_ok=True)
report_path = f"{experiment_dir}/results/validation_report.csv"
summary_df.to_csv(report_path, index=False)

# æ‰“å°ç»“æœ
print("\nğŸ¯ éªŒè¯ç»“æœæ‘˜è¦:")
print("=" * 60)
print(summary_df.to_string(index=False))
print("=" * 60)

# æ£€æŸ¥HEFTæ˜¯å¦åœ¨æ‰€æœ‰æƒ…å†µä¸‹éƒ½ä¼˜äºFIFO
all_heft_wins = (summary_df['improvement_percent'] > 0).all()
if all_heft_wins:
    print("âœ… éªŒè¯æˆåŠŸï¼HEFTåœ¨æ‰€æœ‰æµ‹è¯•åœºæ™¯ä¸­éƒ½ä¼˜äºFIFO")
    print(f"ğŸ“ˆ å¹³å‡æ€§èƒ½æå‡: {summary_df['improvement_percent'].mean():.2f}%")
else:
    print("âŒ éªŒè¯å¤±è´¥ï¼å­˜åœ¨HEFTä¸å¦‚FIFOçš„åœºæ™¯")
    print("è¯·æ£€æŸ¥å®éªŒé…ç½®æˆ–å·¥ä½œæµå‚æ•°")

# ä¿å­˜éªŒè¯çŠ¶æ€
validation_status = {
    'heft_consistently_better': bool(all_heft_wins),
    'average_improvement': float(summary_df['improvement_percent'].mean()),
    'total_scenarios': len(summary_df),
    'successful_scenarios': len(summary_df[summary_df['improvement_percent'] > 0])
}

status_path = f"{experiment_dir}/results/validation_status.json"
with open(status_path, 'w') as f:
    json.dump(validation_status, f, indent=2)

print(f"\nğŸ“‹ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
print(f"ğŸ“Š éªŒè¯çŠ¶æ€å·²ä¿å­˜: {status_path}")
EOF

# å®Œæˆæç¤º
echo ""
echo "ğŸ‰ åŸºå‡†éªŒè¯å®éªŒå®Œæˆï¼"
echo "ğŸ“ ç»“æœç›®å½•: experiments/benchmark_validation/results/"
echo "ğŸ“Š éªŒè¯æŠ¥å‘Š: experiments/benchmark_validation/results/validation_report.csv"
echo "ğŸ” æ£€æŸ¥éªŒè¯çŠ¶æ€: experiments/benchmark_validation/results/validation_status.json"

# å¦‚æœéªŒè¯æˆåŠŸï¼Œæç¤ºä¸‹ä¸€æ­¥æ“ä½œ
if [ -f "experiments/benchmark_validation/results/validation_status.json" ]; then
    if grep -q '"heft_consistently_better": true' "experiments/benchmark_validation/results/validation_status.json"; then
        echo ""
        echo "ğŸš€ éªŒè¯æˆåŠŸï¼ç°åœ¨å¯ä»¥å®‰å…¨åœ°ç»§ç»­ç¬¬ä¸‰æ­¥ï¼š"
        echo "   1. å‡€åŒ–çŸ¥è¯†åº“ï¼ˆä»…ä¿ç•™HEFTå’ŒWassHeuristicSchedulerï¼‰"
        echo "   2. åœ¨src/ai_schedulers.pyä¸­å®ç°R_RAGåŠ¨æ€å¥–åŠ±æœºåˆ¶"
    else
        echo ""
        echo "âš ï¸  éªŒè¯æœªé€šè¿‡ï¼è¯·æ£€æŸ¥å®éªŒé…ç½®æˆ–å·¥ä½œæµå‚æ•°"
        echo "   å»ºè®®ï¼šè°ƒæ•´CCRå€¼æˆ–å·¥ä½œæµè§„æ¨¡åé‡æ–°è¿è¡Œ"
    fi
else
    echo ""
    echo "âŒ éªŒè¯çŠ¶æ€æ–‡ä»¶æœªç”Ÿæˆï¼Œè¯·æ£€æŸ¥å®éªŒè¿‡ç¨‹"
fi